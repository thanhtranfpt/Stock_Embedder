{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For: Using Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import functional as F\n",
    "from einops import rearrange\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('/home/tiennv/FPT/FinanceTransformers')\n",
    "from logger_config import get_logger\n",
    "from stock_embedder import *\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import ta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'pretrained_model_dir': '/home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/models_saved/pretrained',\n",
    "    # Trainer\n",
    "    'stock_data_file': '/home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/Datasets/technology_ver_1.csv',\n",
    "    \"batch_size\": tune.choice([16, 32, 64, 128, 256]),\n",
    "    'split_ratio': 0.8,\n",
    "    'calculate_technical_indicators': False,\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "    \"optimizer\": tune.choice([\"Adam\", \"SGD\"]),\n",
    "    \"momentum\": tune.uniform(0.8, 0.99),\n",
    "    \"weight_decay\": tune.loguniform(1e-5, 1e-3),\n",
    "    \"scheduler\": tune.choice([\"StepLR\", \"ReduceLROnPlateau\"]),\n",
    "    \"step_size\": tune.choice([5, 10, 20]),\n",
    "    \"gamma\": tune.uniform(0.1, 0.5),\n",
    "    # Ray Tune:\n",
    "    'num_samples': 20,\n",
    "    'epochs': 10,\n",
    "    'max_num_epochs': 100,\n",
    "    'gpus_per_trial': 0,\n",
    "    'grace_period': 1,\n",
    "    'reduction_factor': 2,\n",
    "    'device': 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Giải thích:**\n",
    "\n",
    "`max_t=max_num_epochs`: Mỗi thử nghiệm có thể chạy tối đa max_num_epochs epoch.\n",
    "\n",
    "`grace_period=1`: Scheduler sẽ đợi ít nhất 1 epoch trước khi quyết định loại bỏ các thử nghiệm không tốt.\n",
    "\n",
    "`reduction_factor=2`: Sau mỗi giai đoạn, scheduler sẽ giảm số lượng thử nghiệm còn lại xuống một nửa, giúp tập trung vào những thử nghiệm hứa hẹn nhất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ts_size': 24,\n",
       " 'mask_size': 1,\n",
       " 'num_masks': 3,\n",
       " 'total_mask_size': 3,\n",
       " 'hidden_dim': 12,\n",
       " 'embed_dim': 6,\n",
       " 'num_layer': 3,\n",
       " 'z_dim': 6,\n",
       " 'num_embed': 32,\n",
       " 'min_val': array([  49.274517,   50.541279,   49.150326,   49.681866,   49.681866,\n",
       "        7900.      ]),\n",
       " 'max_val': array([1.22172548e+03, 1.22334874e+03, 1.19986969e+03, 1.21864809e+03,\n",
       "        1.21864809e+03, 8.27602000e+07]),\n",
       " 'stock_features': ['Open', 'High', 'Low', 'Close', 'Adj_Close', 'Volume']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = load_model_config(model_dir=config['pretrained_model_dir'])\n",
    "model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*# Bước 1*\n",
    "\n",
    "\n",
    "**Define Models Architecture and Data Loader**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Loader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, ratio):\n",
    "    idx = np.random.permutation(len(data))\n",
    "    train_idx = idx[:int(ratio * len(data))]\n",
    "    test_idx = idx[int(ratio * len(data)):]\n",
    "    train_data = data[train_idx, ...]\n",
    "    test_data = data[test_idx, ...]\n",
    "    return train_data, test_data\n",
    "\n",
    "def load_data(ts_size, data):\n",
    "    # data.shape = (rows, features)\n",
    "    \n",
    "    def sliding_window(ts_size, ori_data):\n",
    "        # Flipping the data to make chronological data\n",
    "        ori_data = ori_data[::-1]  # (len(csv), z_dim)\n",
    "        # Make (len(ori_data), z_dim) into (num_samples, seq_len, z_dim)\n",
    "        samples = []\n",
    "        for i in range(len(ori_data) - ts_size):\n",
    "            single_sample = ori_data[i:i + ts_size]  # (seq_len, z_dim)\n",
    "            samples.append(single_sample)\n",
    "        samples = np.array(samples)  # (bs, seq_len, z_dim)\n",
    "        np.random.shuffle(samples)  # Make it more like i.i.d.\n",
    "        return samples\n",
    "\n",
    "    data = sliding_window(ts_size=ts_size, ori_data=data)  # (bs, ts_size, z_dim)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_technical_indicators(df_passed: pd.DataFrame, rolling_window = 50):\n",
    "    df = df_passed.copy()\n",
    "    \n",
    "    def generate_indicators(df, rolling_window = 50):\n",
    "        # Calculate technical indicators\n",
    "        # df['momentum'] = ta.momentum.roc(df['Close'])\n",
    "        # df['trend'] = ta.trend.sma_indicator(df['Close'])\n",
    "        # df['volatility'] = ta.volatility.bollinger_mavg(df['Close'])\n",
    "        # df['volume'] = ta.volume.on_balance_volume(df['Close'], df['Volume'])\n",
    "        df['stoch'] = ta.momentum.stoch(df['High'], df['Low'], df['Close'])\n",
    "        df['adx'] = ta.trend.adx(df['High'], df['Low'], df['Close'])\n",
    "        df['bollinger_hband'] = ta.volatility.bollinger_hband(df['Close'])\n",
    "        df['mfi'] = ta.volume.money_flow_index(df['High'], df['Low'], df['Close'], df['Volume'])\n",
    "        df['rsi'] = ta.momentum.rsi(df['Close'])\n",
    "        df['ma'] = ta.trend.sma_indicator(df['Close'])\n",
    "        df['std'] = df['Close'].rolling(window=rolling_window).std()\n",
    "        df['adl'] = ta.volume.acc_dist_index(df['High'], df['Low'], df['Close'], df['Volume'])\n",
    "        df['williams'] = ta.momentum.williams_r(df['High'], df['Low'], df['Close'])\n",
    "        df['macd'] = ta.trend.macd(df['Close'])\n",
    "        df['obv'] = ta.volume.on_balance_volume(df['Close'], df['Volume'])\n",
    "        df['sar'] = ta.trend.psar_down(df['High'], df['Low'], df['Close']) # Added the 'close' argument\n",
    "        df['ichimoku_a'] = ta.trend.ichimoku_a(df['High'], df['Low'])\n",
    "        df['ichimoku_b'] = ta.trend.ichimoku_b(df['High'], df['Low'])\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df = generate_indicators(df=df, rolling_window=rolling_window)\n",
    "    \n",
    "    # Fillna\n",
    "    df = df.fillna(method='ffill')\n",
    "    df = df.iloc[rolling_window + 1 : ]\n",
    "    df = df.fillna(method='bfill')\n",
    "    \n",
    "    if df.isna().sum().sum() > 0:\n",
    "        raise Exception('NaN values found')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>JBL</td>\n",
       "      <td>14.340293</td>\n",
       "      <td>17.040001</td>\n",
       "      <td>17.620001</td>\n",
       "      <td>16.940001</td>\n",
       "      <td>17.610001</td>\n",
       "      <td>3682500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>FSLR</td>\n",
       "      <td>138.240005</td>\n",
       "      <td>138.240005</td>\n",
       "      <td>141.240005</td>\n",
       "      <td>137.770004</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>1575400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>FI</td>\n",
       "      <td>12.227500</td>\n",
       "      <td>12.227500</td>\n",
       "      <td>12.245000</td>\n",
       "      <td>12.125000</td>\n",
       "      <td>12.190000</td>\n",
       "      <td>5786000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>IT</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>20.309999</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>MCHP</td>\n",
       "      <td>9.767199</td>\n",
       "      <td>14.230000</td>\n",
       "      <td>14.285000</td>\n",
       "      <td>14.090000</td>\n",
       "      <td>14.245000</td>\n",
       "      <td>4489600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261364</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>ADI</td>\n",
       "      <td>199.815201</td>\n",
       "      <td>200.610001</td>\n",
       "      <td>204.199997</td>\n",
       "      <td>200.500000</td>\n",
       "      <td>203.630005</td>\n",
       "      <td>2668400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261365</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>169.240005</td>\n",
       "      <td>165.809998</td>\n",
       "      <td>169.229996</td>\n",
       "      <td>6914200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261366</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>INTU</td>\n",
       "      <td>625.619995</td>\n",
       "      <td>625.619995</td>\n",
       "      <td>637.919983</td>\n",
       "      <td>625.229980</td>\n",
       "      <td>637.010010</td>\n",
       "      <td>1309700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261367</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>FTV</td>\n",
       "      <td>75.188156</td>\n",
       "      <td>75.269997</td>\n",
       "      <td>77.105003</td>\n",
       "      <td>75.220001</td>\n",
       "      <td>77.010002</td>\n",
       "      <td>2356300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261368</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>IT</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>458.079987</td>\n",
       "      <td>411.149994</td>\n",
       "      <td>458.059998</td>\n",
       "      <td>1344200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261369 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Symbol   Adj Close       Close        High         Low  \\\n",
       "0       2010-01-11    JBL   14.340293   17.040001   17.620001   16.940001   \n",
       "1       2010-01-11   FSLR  138.240005  138.240005  141.240005  137.770004   \n",
       "2       2010-01-11     FI   12.227500   12.227500   12.245000   12.125000   \n",
       "3       2010-01-11     IT   20.600000   20.600000   20.690001   20.309999   \n",
       "4       2010-01-11   MCHP    9.767199   14.230000   14.285000   14.090000   \n",
       "...            ...    ...         ...         ...         ...         ...   \n",
       "261364  2024-04-30    ADI  199.815201  200.610001  204.199997  200.500000   \n",
       "261365  2024-04-30   QCOM  165.850006  165.850006  169.240005  165.809998   \n",
       "261366  2024-04-30   INTU  625.619995  625.619995  637.919983  625.229980   \n",
       "261367  2024-04-30    FTV   75.188156   75.269997   77.105003   75.220001   \n",
       "261368  2024-04-30     IT  412.589996  412.589996  458.079987  411.149994   \n",
       "\n",
       "              Open     Volume  \n",
       "0        17.610001  3682500.0  \n",
       "1       141.000000  1575400.0  \n",
       "2        12.190000  5786000.0  \n",
       "3        20.690001   386400.0  \n",
       "4        14.245000  4489600.0  \n",
       "...            ...        ...  \n",
       "261364  203.630005  2668400.0  \n",
       "261365  169.229996  6914200.0  \n",
       "261366  637.010010  1309700.0  \n",
       "261367   77.010002  2356300.0  \n",
       "261368  458.059998  1344200.0  \n",
       "\n",
       "[261369 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_symbols_df = pd.read_csv(config['stock_data_file'], encoding='UTF-8')\n",
    "all_symbols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>JBL</td>\n",
       "      <td>14.340293</td>\n",
       "      <td>17.040001</td>\n",
       "      <td>17.620001</td>\n",
       "      <td>16.940001</td>\n",
       "      <td>17.610001</td>\n",
       "      <td>3682500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>FSLR</td>\n",
       "      <td>138.240005</td>\n",
       "      <td>138.240005</td>\n",
       "      <td>141.240005</td>\n",
       "      <td>137.770004</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>1575400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>FI</td>\n",
       "      <td>12.227500</td>\n",
       "      <td>12.227500</td>\n",
       "      <td>12.245000</td>\n",
       "      <td>12.125000</td>\n",
       "      <td>12.190000</td>\n",
       "      <td>5786000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>IT</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>20.309999</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>MCHP</td>\n",
       "      <td>9.767199</td>\n",
       "      <td>14.230000</td>\n",
       "      <td>14.285000</td>\n",
       "      <td>14.090000</td>\n",
       "      <td>14.245000</td>\n",
       "      <td>4489600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261364</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>ADI</td>\n",
       "      <td>199.815201</td>\n",
       "      <td>200.610001</td>\n",
       "      <td>204.199997</td>\n",
       "      <td>200.500000</td>\n",
       "      <td>203.630005</td>\n",
       "      <td>2668400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261365</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>169.240005</td>\n",
       "      <td>165.809998</td>\n",
       "      <td>169.229996</td>\n",
       "      <td>6914200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261366</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>INTU</td>\n",
       "      <td>625.619995</td>\n",
       "      <td>625.619995</td>\n",
       "      <td>637.919983</td>\n",
       "      <td>625.229980</td>\n",
       "      <td>637.010010</td>\n",
       "      <td>1309700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261367</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>FTV</td>\n",
       "      <td>75.188156</td>\n",
       "      <td>75.269997</td>\n",
       "      <td>77.105003</td>\n",
       "      <td>75.220001</td>\n",
       "      <td>77.010002</td>\n",
       "      <td>2356300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261368</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>IT</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>458.079987</td>\n",
       "      <td>411.149994</td>\n",
       "      <td>458.059998</td>\n",
       "      <td>1344200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261369 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Symbol   Adj Close       Close        High         Low  \\\n",
       "0      2010-01-11    JBL   14.340293   17.040001   17.620001   16.940001   \n",
       "1      2010-01-11   FSLR  138.240005  138.240005  141.240005  137.770004   \n",
       "2      2010-01-11     FI   12.227500   12.227500   12.245000   12.125000   \n",
       "3      2010-01-11     IT   20.600000   20.600000   20.690001   20.309999   \n",
       "4      2010-01-11   MCHP    9.767199   14.230000   14.285000   14.090000   \n",
       "...           ...    ...         ...         ...         ...         ...   \n",
       "261364 2024-04-30    ADI  199.815201  200.610001  204.199997  200.500000   \n",
       "261365 2024-04-30   QCOM  165.850006  165.850006  169.240005  165.809998   \n",
       "261366 2024-04-30   INTU  625.619995  625.619995  637.919983  625.229980   \n",
       "261367 2024-04-30    FTV   75.188156   75.269997   77.105003   75.220001   \n",
       "261368 2024-04-30     IT  412.589996  412.589996  458.079987  411.149994   \n",
       "\n",
       "              Open     Volume  \n",
       "0        17.610001  3682500.0  \n",
       "1       141.000000  1575400.0  \n",
       "2        12.190000  5786000.0  \n",
       "3        20.690001   386400.0  \n",
       "4        14.245000  4489600.0  \n",
       "...            ...        ...  \n",
       "261364  203.630005  2668400.0  \n",
       "261365  169.229996  6914200.0  \n",
       "261366  637.010010  1309700.0  \n",
       "261367   77.010002  2356300.0  \n",
       "261368  458.059998  1344200.0  \n",
       "\n",
       "[261369 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_symbols_df['Date'] = pd.to_datetime(all_symbols_df['Date'])\n",
    "all_symbols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>JBL</td>\n",
       "      <td>14.340293</td>\n",
       "      <td>17.040001</td>\n",
       "      <td>17.620001</td>\n",
       "      <td>16.940001</td>\n",
       "      <td>17.610001</td>\n",
       "      <td>3682500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>ADSK</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>26.490000</td>\n",
       "      <td>26.070000</td>\n",
       "      <td>26.340000</td>\n",
       "      <td>2151300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>GRMN</td>\n",
       "      <td>21.318253</td>\n",
       "      <td>34.290001</td>\n",
       "      <td>34.450001</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>34.099998</td>\n",
       "      <td>1997700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>APH</td>\n",
       "      <td>5.031209</td>\n",
       "      <td>5.661250</td>\n",
       "      <td>5.692500</td>\n",
       "      <td>5.575000</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>6540800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>GLW</td>\n",
       "      <td>14.353989</td>\n",
       "      <td>20.490000</td>\n",
       "      <td>20.850000</td>\n",
       "      <td>20.219999</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>25617100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261313</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>170.099289</td>\n",
       "      <td>170.330002</td>\n",
       "      <td>174.990005</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>173.330002</td>\n",
       "      <td>65934800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261312</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>ENPH</td>\n",
       "      <td>108.760002</td>\n",
       "      <td>108.760002</td>\n",
       "      <td>111.949997</td>\n",
       "      <td>108.690002</td>\n",
       "      <td>111.250000</td>\n",
       "      <td>2768300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261311</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>MSI</td>\n",
       "      <td>339.149994</td>\n",
       "      <td>339.149994</td>\n",
       "      <td>347.070007</td>\n",
       "      <td>338.540009</td>\n",
       "      <td>346.700012</td>\n",
       "      <td>1220800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261318</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>APH</td>\n",
       "      <td>60.288956</td>\n",
       "      <td>60.384998</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>60.349998</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>7167200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261368</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>IT</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>458.079987</td>\n",
       "      <td>411.149994</td>\n",
       "      <td>458.059998</td>\n",
       "      <td>1344200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261369 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Symbol   Adj Close       Close        High         Low  \\\n",
       "0      2010-01-11    JBL   14.340293   17.040001   17.620001   16.940001   \n",
       "33     2010-01-11   ADSK   26.250000   26.250000   26.490000   26.070000   \n",
       "34     2010-01-11   GRMN   21.318253   34.290001   34.450001   33.520000   \n",
       "35     2010-01-11    APH    5.031209    5.661250    5.692500    5.575000   \n",
       "36     2010-01-11    GLW   14.353989   20.490000   20.850000   20.219999   \n",
       "...           ...    ...         ...         ...         ...         ...   \n",
       "261313 2024-04-30   AAPL  170.099289  170.330002  174.990005  170.000000   \n",
       "261312 2024-04-30   ENPH  108.760002  108.760002  111.949997  108.690002   \n",
       "261311 2024-04-30    MSI  339.149994  339.149994  347.070007  338.540009   \n",
       "261318 2024-04-30    APH   60.288956   60.384998   61.799999   60.349998   \n",
       "261368 2024-04-30     IT  412.589996  412.589996  458.079987  411.149994   \n",
       "\n",
       "              Open      Volume  \n",
       "0        17.610001   3682500.0  \n",
       "33       26.340000   2151300.0  \n",
       "34       34.099998   1997700.0  \n",
       "35        5.680000   6540800.0  \n",
       "36       20.620001  25617100.0  \n",
       "...            ...         ...  \n",
       "261313  173.330002  65934800.0  \n",
       "261312  111.250000   2768300.0  \n",
       "261311  346.700012   1220800.0  \n",
       "261318   61.000000   7167200.0  \n",
       "261368  458.059998   1344200.0  \n",
       "\n",
       "[261369 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_symbols_df = all_symbols_df.sort_values(by='Date')\n",
    "all_symbols_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Choose Dates Range*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82033</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>TER</td>\n",
       "      <td>18.421520</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.469999</td>\n",
       "      <td>19.920000</td>\n",
       "      <td>1030300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82039</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>LRCX</td>\n",
       "      <td>69.079231</td>\n",
       "      <td>79.449997</td>\n",
       "      <td>80.190002</td>\n",
       "      <td>78.839996</td>\n",
       "      <td>79.870003</td>\n",
       "      <td>830600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82038</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ADI</td>\n",
       "      <td>45.454937</td>\n",
       "      <td>55.540001</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>54.970001</td>\n",
       "      <td>55.680000</td>\n",
       "      <td>1323200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82037</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>MSI</td>\n",
       "      <td>58.383911</td>\n",
       "      <td>66.510002</td>\n",
       "      <td>67.730003</td>\n",
       "      <td>66.360001</td>\n",
       "      <td>67.540001</td>\n",
       "      <td>1077900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82036</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>CDW</td>\n",
       "      <td>31.416943</td>\n",
       "      <td>34.860001</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>34.599998</td>\n",
       "      <td>35.259998</td>\n",
       "      <td>380200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100323</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>17.243118</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>18.959999</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>18.940001</td>\n",
       "      <td>8685100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100322</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>NXPI</td>\n",
       "      <td>76.961082</td>\n",
       "      <td>84.250000</td>\n",
       "      <td>85.870003</td>\n",
       "      <td>84.150002</td>\n",
       "      <td>85.430000</td>\n",
       "      <td>2140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100321</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>MCHP</td>\n",
       "      <td>20.020269</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>23.924999</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>23.825001</td>\n",
       "      <td>2316200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100320</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>JBL</td>\n",
       "      <td>21.590118</td>\n",
       "      <td>23.290001</td>\n",
       "      <td>23.629999</td>\n",
       "      <td>23.290001</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>1559900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100327</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>TXN</td>\n",
       "      <td>47.133926</td>\n",
       "      <td>54.810001</td>\n",
       "      <td>56.299999</td>\n",
       "      <td>54.810001</td>\n",
       "      <td>56.049999</td>\n",
       "      <td>6450100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18388 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Symbol  Adj Close      Close       High        Low  \\\n",
       "82033  2015-01-02    TER  18.421520  19.700001  20.000000  19.469999   \n",
       "82039  2015-01-02   LRCX  69.079231  79.449997  80.190002  78.839996   \n",
       "82038  2015-01-02    ADI  45.454937  55.540001  56.250000  54.970001   \n",
       "82037  2015-01-02    MSI  58.383911  66.510002  67.730003  66.360001   \n",
       "82036  2015-01-02    CDW  31.416943  34.860001  35.299999  34.599998   \n",
       "...           ...    ...        ...        ...        ...        ...   \n",
       "100323 2015-12-31   AMAT  17.243118  18.670000  18.959999  18.670000   \n",
       "100322 2015-12-31   NXPI  76.961082  84.250000  85.870003  84.150002   \n",
       "100321 2015-12-31   MCHP  20.020269  23.270000  23.924999  23.270000   \n",
       "100320 2015-12-31    JBL  21.590118  23.290001  23.629999  23.290001   \n",
       "100327 2015-12-31    TXN  47.133926  54.810001  56.299999  54.810001   \n",
       "\n",
       "             Open     Volume  \n",
       "82033   19.920000  1030300.0  \n",
       "82039   79.870003   830600.0  \n",
       "82038   55.680000  1323200.0  \n",
       "82037   67.540001  1077900.0  \n",
       "82036   35.259998   380200.0  \n",
       "...           ...        ...  \n",
       "100323  18.940001  8685100.0  \n",
       "100322  85.430000  2140000.0  \n",
       "100321  23.825001  2316200.0  \n",
       "100320  23.500000  1559900.0  \n",
       "100327  56.049999  6450100.0  \n",
       "\n",
       "[18388 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = '2015-01-01'\n",
    "end_date = '2016-01-01'\n",
    "\n",
    "all_symbols_df = all_symbols_df[(all_symbols_df['Date'] >= start_date) & (all_symbols_df['Date'] <= end_date)]\n",
    "all_symbols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open', 'High', 'Low', 'Close', 'Adj_Close', 'Volume']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config['stock_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2853605/3436076750.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_symbols_df.rename(columns={'Adj Close': 'Adj_Close'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82033</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>TER</td>\n",
       "      <td>18.421520</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.469999</td>\n",
       "      <td>19.920000</td>\n",
       "      <td>1030300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82039</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>LRCX</td>\n",
       "      <td>69.079231</td>\n",
       "      <td>79.449997</td>\n",
       "      <td>80.190002</td>\n",
       "      <td>78.839996</td>\n",
       "      <td>79.870003</td>\n",
       "      <td>830600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82038</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ADI</td>\n",
       "      <td>45.454937</td>\n",
       "      <td>55.540001</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>54.970001</td>\n",
       "      <td>55.680000</td>\n",
       "      <td>1323200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82037</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>MSI</td>\n",
       "      <td>58.383911</td>\n",
       "      <td>66.510002</td>\n",
       "      <td>67.730003</td>\n",
       "      <td>66.360001</td>\n",
       "      <td>67.540001</td>\n",
       "      <td>1077900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82036</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>CDW</td>\n",
       "      <td>31.416943</td>\n",
       "      <td>34.860001</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>34.599998</td>\n",
       "      <td>35.259998</td>\n",
       "      <td>380200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100323</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>17.243118</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>18.959999</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>18.940001</td>\n",
       "      <td>8685100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100322</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>NXPI</td>\n",
       "      <td>76.961082</td>\n",
       "      <td>84.250000</td>\n",
       "      <td>85.870003</td>\n",
       "      <td>84.150002</td>\n",
       "      <td>85.430000</td>\n",
       "      <td>2140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100321</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>MCHP</td>\n",
       "      <td>20.020269</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>23.924999</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>23.825001</td>\n",
       "      <td>2316200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100320</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>JBL</td>\n",
       "      <td>21.590118</td>\n",
       "      <td>23.290001</td>\n",
       "      <td>23.629999</td>\n",
       "      <td>23.290001</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>1559900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100327</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>TXN</td>\n",
       "      <td>47.133926</td>\n",
       "      <td>54.810001</td>\n",
       "      <td>56.299999</td>\n",
       "      <td>54.810001</td>\n",
       "      <td>56.049999</td>\n",
       "      <td>6450100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18388 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Symbol  Adj_Close      Close       High        Low  \\\n",
       "82033  2015-01-02    TER  18.421520  19.700001  20.000000  19.469999   \n",
       "82039  2015-01-02   LRCX  69.079231  79.449997  80.190002  78.839996   \n",
       "82038  2015-01-02    ADI  45.454937  55.540001  56.250000  54.970001   \n",
       "82037  2015-01-02    MSI  58.383911  66.510002  67.730003  66.360001   \n",
       "82036  2015-01-02    CDW  31.416943  34.860001  35.299999  34.599998   \n",
       "...           ...    ...        ...        ...        ...        ...   \n",
       "100323 2015-12-31   AMAT  17.243118  18.670000  18.959999  18.670000   \n",
       "100322 2015-12-31   NXPI  76.961082  84.250000  85.870003  84.150002   \n",
       "100321 2015-12-31   MCHP  20.020269  23.270000  23.924999  23.270000   \n",
       "100320 2015-12-31    JBL  21.590118  23.290001  23.629999  23.290001   \n",
       "100327 2015-12-31    TXN  47.133926  54.810001  56.299999  54.810001   \n",
       "\n",
       "             Open     Volume  \n",
       "82033   19.920000  1030300.0  \n",
       "82039   79.870003   830600.0  \n",
       "82038   55.680000  1323200.0  \n",
       "82037   67.540001  1077900.0  \n",
       "82036   35.259998   380200.0  \n",
       "...           ...        ...  \n",
       "100323  18.940001  8685100.0  \n",
       "100322  85.430000  2140000.0  \n",
       "100321  23.825001  2316200.0  \n",
       "100320  23.500000  1559900.0  \n",
       "100327  56.049999  6450100.0  \n",
       "\n",
       "[18388 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_symbols_df.rename(columns={'Adj Close': 'Adj_Close'}, inplace=True)\n",
    "all_symbols_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create Training and Validation Batches*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6dcd44db8d468fb1da14e1ada28b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_batches = torch.tensor(data=[])\n",
    "val_batches = torch.tensor(data=[])\n",
    "\n",
    "symbols = all_symbols_df['Symbol'].unique()\n",
    "\n",
    "for symbol in tqdm(symbols):\n",
    "    df = all_symbols_df[all_symbols_df['Symbol'] == symbol]\n",
    "    df = df.sort_values(by='Date')\n",
    "    \n",
    "    if config['calculate_technical_indicators']:\n",
    "        df = calculate_technical_indicators(df, rolling_window=model_config['ts_size'])\n",
    "    \n",
    "    df = df[model_config['stock_features']]\n",
    "    data = df.values\n",
    "    \n",
    "    train_data, val_data = train_test_split(data=data, ratio=config['split_ratio'])\n",
    "    \n",
    "    # Create batches (sliding window)\n",
    "    train_data = load_data(ts_size=model_config['ts_size'], data=train_data)\n",
    "    val_data = load_data(ts_size=model_config['ts_size'], data=val_data)\n",
    "    \n",
    "    if len(train_data) > 0:\n",
    "        train_data = normalize(train_data, min_val=model_config['min_val'], max_val=model_config['max_val'])\n",
    "        train_data = torch.tensor(train_data)\n",
    "        train_batches = torch.cat(tensors=[train_batches, train_data])\n",
    "    \n",
    "    if len(val_data) > 0:\n",
    "        val_data = normalize(val_data, min_val=model_config['min_val'], max_val=model_config['max_val'])\n",
    "        val_data = torch.tensor(val_data)\n",
    "        val_batches = torch.cat(tensors=[val_batches, val_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Models Architecture*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mini_batch(batch_size, data):\n",
    "    idx = np.random.permutation(len(data))\n",
    "    idx = idx[:batch_size]\n",
    "    data_mini = data[idx, ...]  # (bs, seq_len, z_dim)\n",
    "    return data_mini\n",
    "\n",
    "def generate_random_masks(num_samples, ts_size, mask_size, num_masks):\n",
    "    # xxxo\n",
    "    # oxxx\n",
    "    # xxox\n",
    "    num_patches = int(ts_size // mask_size)\n",
    "\n",
    "    def single_sample_mask():\n",
    "        idx = np.random.permutation(num_patches)[:num_masks]\n",
    "        mask = np.zeros(ts_size, dtype=bool)\n",
    "        for j in idx:\n",
    "            mask[j * mask_size:(j + 1) * mask_size] = 1\n",
    "        return mask\n",
    "\n",
    "    masks_list = [single_sample_mask() for _ in range(num_samples)]\n",
    "    masks_list = [torch.tensor(mask) for mask in masks_list]\n",
    "    masks = torch.stack(masks_list, axis=0)  # (num_samples, ts_size)\n",
    "    return masks\n",
    "\n",
    "def generate_pseudo_masks(ts_size, num_samples):\n",
    "    # xxxx\n",
    "    # xxxx\n",
    "    # xxxx\n",
    "    masks = np.zeros((num_samples, ts_size), dtype=bool)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ray Tune**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 21:59:39,458\tINFO worker.py:1786 -- Started a local Ray instance.\n",
      "2024-09-22 21:59:40,416\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-09-22 21:59:40,418\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "/home/tiennv/.conda/envs/FinTrans/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-09-22 21:59:58</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:17.54        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.7/62.6 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=18<br>Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: -0.03356709106035433 | Iter 4.000: -0.03421880635614499 | Iter 2.000: -0.034816807469083035 | Iter 1.000: -0.03554427519823851<br>Logical resource usage: 1.0/24 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">   gamma</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th><th>optimizer  </th><th>scheduler        </th><th style=\"text-align: right;\">  step_size</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_4b3ad_00000</td><td>TERMINATED</td><td>192.168.2.115:2862487</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.148858</td><td style=\"text-align: right;\">0.00043122 </td><td style=\"text-align: right;\">  0.912965</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   5.48646e-05</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         6.54748</td><td style=\"text-align: right;\">0.0334539</td></tr>\n",
       "<tr><td>train_model_4b3ad_00001</td><td>TERMINATED</td><td>192.168.2.115:2862489</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.471821</td><td style=\"text-align: right;\">0.000484726</td><td style=\"text-align: right;\">  0.960113</td><td>SGD        </td><td>StepLR           </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   2.04044e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.10994</td><td style=\"text-align: right;\">0.0384892</td></tr>\n",
       "<tr><td>train_model_4b3ad_00002</td><td>TERMINATED</td><td>192.168.2.115:2862490</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.185782</td><td style=\"text-align: right;\">0.000103949</td><td style=\"text-align: right;\">  0.913394</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">   0.000194447</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.1533 </td><td style=\"text-align: right;\">0.0383927</td></tr>\n",
       "<tr><td>train_model_4b3ad_00003</td><td>TERMINATED</td><td>192.168.2.115:2862495</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.193691</td><td style=\"text-align: right;\">0.00775389 </td><td style=\"text-align: right;\">  0.927245</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   1.19615e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.2115 </td><td style=\"text-align: right;\">0.225209 </td></tr>\n",
       "<tr><td>train_model_4b3ad_00004</td><td>TERMINATED</td><td>192.168.2.115:2862494</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.242172</td><td style=\"text-align: right;\">0.00020564 </td><td style=\"text-align: right;\">  0.861605</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">   0.000358674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.0243 </td><td style=\"text-align: right;\">0.0347919</td></tr>\n",
       "<tr><td>train_model_4b3ad_00005</td><td>TERMINATED</td><td>192.168.2.115:2862493</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.328982</td><td style=\"text-align: right;\">0.00146963 </td><td style=\"text-align: right;\">  0.957959</td><td>SGD        </td><td>StepLR           </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   1.04891e-05</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         2.42563</td><td style=\"text-align: right;\">0.0351425</td></tr>\n",
       "<tr><td>train_model_4b3ad_00006</td><td>TERMINATED</td><td>192.168.2.115:2862496</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.442288</td><td style=\"text-align: right;\">0.000948089</td><td style=\"text-align: right;\">  0.800161</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">   0.000598948</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.13594</td><td style=\"text-align: right;\">0.0358585</td></tr>\n",
       "<tr><td>train_model_4b3ad_00007</td><td>TERMINATED</td><td>192.168.2.115:2862499</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.443678</td><td style=\"text-align: right;\">0.000381704</td><td style=\"text-align: right;\">  0.898661</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">   0.000104699</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         6.51936</td><td style=\"text-align: right;\">0.0331546</td></tr>\n",
       "<tr><td>train_model_4b3ad_00008</td><td>TERMINATED</td><td>192.168.2.115:2862502</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.464757</td><td style=\"text-align: right;\">0.000136277</td><td style=\"text-align: right;\">  0.980367</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">   3.61004e-05</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         4.71392</td><td style=\"text-align: right;\">0.0347408</td></tr>\n",
       "<tr><td>train_model_4b3ad_00009</td><td>TERMINATED</td><td>192.168.2.115:2862506</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.138449</td><td style=\"text-align: right;\">0.00402469 </td><td style=\"text-align: right;\">  0.944095</td><td>SGD        </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">   0.000248221</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         2.85906</td><td style=\"text-align: right;\">0.0351495</td></tr>\n",
       "<tr><td>train_model_4b3ad_00010</td><td>TERMINATED</td><td>192.168.2.115:2862507</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.100803</td><td style=\"text-align: right;\">0.00360154 </td><td style=\"text-align: right;\">  0.862236</td><td>SGD        </td><td>StepLR           </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.000309071</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.03263</td><td style=\"text-align: right;\">0.0385248</td></tr>\n",
       "<tr><td>train_model_4b3ad_00011</td><td>TERMINATED</td><td>192.168.2.115:2862508</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.124083</td><td style=\"text-align: right;\">0.00227936 </td><td style=\"text-align: right;\">  0.937985</td><td>SGD        </td><td>StepLR           </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   2.41764e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.94332</td><td style=\"text-align: right;\">0.0359559</td></tr>\n",
       "<tr><td>train_model_4b3ad_00012</td><td>TERMINATED</td><td>192.168.2.115:2862510</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.197523</td><td style=\"text-align: right;\">0.000280794</td><td style=\"text-align: right;\">  0.937004</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">   0.000415415</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.9825 </td><td style=\"text-align: right;\">0.0355905</td></tr>\n",
       "<tr><td>train_model_4b3ad_00013</td><td>TERMINATED</td><td>192.168.2.115:2862511</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.312341</td><td style=\"text-align: right;\">0.00058261 </td><td style=\"text-align: right;\">  0.947373</td><td>SGD        </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   1.56846e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.17071</td><td style=\"text-align: right;\">0.0385388</td></tr>\n",
       "<tr><td>train_model_4b3ad_00014</td><td>TERMINATED</td><td>192.168.2.115:2862513</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.100499</td><td style=\"text-align: right;\">0.000143057</td><td style=\"text-align: right;\">  0.806031</td><td>SGD        </td><td>StepLR           </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">   9.15725e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.94595</td><td style=\"text-align: right;\">0.0359608</td></tr>\n",
       "<tr><td>train_model_4b3ad_00015</td><td>TERMINATED</td><td>192.168.2.115:2862515</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.339509</td><td style=\"text-align: right;\">0.000244116</td><td style=\"text-align: right;\">  0.881273</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">   4.05906e-05</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         4.00593</td><td style=\"text-align: right;\">0.0342577</td></tr>\n",
       "<tr><td>train_model_4b3ad_00016</td><td>TERMINATED</td><td>192.168.2.115:2862517</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.427905</td><td style=\"text-align: right;\">0.00117366 </td><td style=\"text-align: right;\">  0.884628</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">   0.00090977 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.05441</td><td style=\"text-align: right;\">0.036767 </td></tr>\n",
       "<tr><td>train_model_4b3ad_00017</td><td>TERMINATED</td><td>192.168.2.115:2862518</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.459121</td><td style=\"text-align: right;\">0.000245429</td><td style=\"text-align: right;\">  0.884801</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">   0.000136584</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         2.84188</td><td style=\"text-align: right;\">0.0348168</td></tr>\n",
       "<tr><td>train_model_4b3ad_00018</td><td>TERMINATED</td><td>192.168.2.115:2862527</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.466874</td><td style=\"text-align: right;\">0.00779327 </td><td style=\"text-align: right;\">  0.8305  </td><td>SGD        </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   2.19547e-05</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         2.64948</td><td style=\"text-align: right;\">0.0348797</td></tr>\n",
       "<tr><td>train_model_4b3ad_00019</td><td>TERMINATED</td><td>192.168.2.115:2862529</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.490031</td><td style=\"text-align: right;\">0.000631579</td><td style=\"text-align: right;\">  0.884678</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">   7.22419e-05</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         2.71359</td><td style=\"text-align: right;\">0.0352137</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (32 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=2862502)\u001b[0m /home/tiennv/.conda/envs/FinTrans/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(pid=2862502)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(train_model pid=2862502)\u001b[0m   model.load_state_dict(state_dict=torch.load(f=os.path.join(model_dir, 'model.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=2862502)\u001b[0m   0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=2862502)\u001b[0m /tmp/ipykernel_2853605/2894700186.py:167: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[36m(train_model pid=2862502)\u001b[0m /home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/stock_embedder.py:139: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[36m(train_model pid=2862502)\u001b[0m   x = torch.tensor(x, dtype=torch.float32)\n",
      "\u001b[36m(train_model pid=2862502)\u001b[0m /home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/stock_embedder.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[36m(train_model pid=2862502)\u001b[0m   masks = torch.tensor(masks, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">     loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_4b3ad_00000</td><td style=\"text-align: right;\">0.0334539</td></tr>\n",
       "<tr><td>train_model_4b3ad_00001</td><td style=\"text-align: right;\">0.0384892</td></tr>\n",
       "<tr><td>train_model_4b3ad_00002</td><td style=\"text-align: right;\">0.0383927</td></tr>\n",
       "<tr><td>train_model_4b3ad_00003</td><td style=\"text-align: right;\">0.225209 </td></tr>\n",
       "<tr><td>train_model_4b3ad_00004</td><td style=\"text-align: right;\">0.0347919</td></tr>\n",
       "<tr><td>train_model_4b3ad_00005</td><td style=\"text-align: right;\">0.0351425</td></tr>\n",
       "<tr><td>train_model_4b3ad_00006</td><td style=\"text-align: right;\">0.0358585</td></tr>\n",
       "<tr><td>train_model_4b3ad_00007</td><td style=\"text-align: right;\">0.0331546</td></tr>\n",
       "<tr><td>train_model_4b3ad_00008</td><td style=\"text-align: right;\">0.0347408</td></tr>\n",
       "<tr><td>train_model_4b3ad_00009</td><td style=\"text-align: right;\">0.0351495</td></tr>\n",
       "<tr><td>train_model_4b3ad_00010</td><td style=\"text-align: right;\">0.0385248</td></tr>\n",
       "<tr><td>train_model_4b3ad_00011</td><td style=\"text-align: right;\">0.0359559</td></tr>\n",
       "<tr><td>train_model_4b3ad_00012</td><td style=\"text-align: right;\">0.0355905</td></tr>\n",
       "<tr><td>train_model_4b3ad_00013</td><td style=\"text-align: right;\">0.0385388</td></tr>\n",
       "<tr><td>train_model_4b3ad_00014</td><td style=\"text-align: right;\">0.0359608</td></tr>\n",
       "<tr><td>train_model_4b3ad_00015</td><td style=\"text-align: right;\">0.0342577</td></tr>\n",
       "<tr><td>train_model_4b3ad_00016</td><td style=\"text-align: right;\">0.036767 </td></tr>\n",
       "<tr><td>train_model_4b3ad_00017</td><td style=\"text-align: right;\">0.0348168</td></tr>\n",
       "<tr><td>train_model_4b3ad_00018</td><td style=\"text-align: right;\">0.0348797</td></tr>\n",
       "<tr><td>train_model_4b3ad_00019</td><td style=\"text-align: right;\">0.0352137</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 21:59:58,298\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/tiennv/ray_results/train_model_2024-09-22_21-59-40' in 0.0203s.\n",
      "2024-09-22 21:59:58,309\tINFO tune.py:1041 -- Total run time: 17.89 seconds (17.52 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'pretrained_model_dir': '/home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/models_saved/pretrained', 'stock_data_file': '/home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/Datasets/technology_ver_1.csv', 'batch_size': 16, 'split_ratio': 0.8, 'calculate_technical_indicators': False, 'lr': 0.00038170387616976386, 'optimizer': 'Adam', 'momentum': 0.8986611460040892, 'weight_decay': 0.00010469943492750553, 'scheduler': 'ReduceLROnPlateau', 'step_size': 10, 'gamma': 0.4436783435351249, 'num_samples': 20, 'epochs': 10, 'max_num_epochs': 100, 'gpus_per_trial': 0, 'grace_period': 1, 'reduction_factor': 2, 'device': 'cpu'}\n",
      "Best trial final validation loss: 0.03315458196871599\n"
     ]
    }
   ],
   "source": [
    "import ray.train\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "\n",
    "\n",
    "# Bước 2: Hàm training với Ray Tune và validation\n",
    "def train_model(config, checkpoint_dir=None):\n",
    "    # ---------------- Get Model ------------\n",
    "    model = StockEmbedder(config=model_config)\n",
    "    model = load_model(model=model, model_dir=config['pretrained_model_dir'])\n",
    "    # ---------------- END OF: Get Model -------------\n",
    "    \n",
    "    criterion = torch.nn.MSELoss(reduction='mean')\n",
    "    optimizer = getattr(optim, config[\"optimizer\"])(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    # Chỉ dùng momentum nếu optimizer là SGD\n",
    "    if config[\"optimizer\"] == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    # Load checkpoint nếu có\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = torch.load(checkpoint_dir)\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "    \n",
    "    \n",
    "    pseudo_masks = generate_pseudo_masks(ts_size=model.config['ts_size'], num_samples=config['batch_size'])\n",
    "    \n",
    "    # ------------------- TRAIN AE ----------------------------\n",
    "    # for t in tqdm(range(config['epochs'])):\n",
    "    #     # ------------ Train model: -----------------\n",
    "    #     # Đặt mô hình về chế độ train để huấn luyện\n",
    "    #     model.train()\n",
    "        \n",
    "    #     x_ori = get_mini_batch(batch_size=config['batch_size'], data=train_batches)  # (bs, ts_size, z_dim)\n",
    "        \n",
    "    #     x_ori = torch.tensor(x_ori, dtype=torch.float32).to(config['device'])\n",
    "    #     x_enc, x_dec = model(x_ori, pseudo_masks, 'ae')\n",
    "    #     loss = criterion(x_dec, x_ori)\n",
    "        \n",
    "    #     optimizer.zero_grad()\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()\n",
    "        \n",
    "    #     # -------------- END OF: Train model -----------------\n",
    "    #     # ------------- Calculate loss on validation set: -----------------------\n",
    "    #     model.eval()\n",
    "        \n",
    "    #     val_loss = 0\n",
    "        \n",
    "    #     num_batches = len(val_batches) // config['batch_size']\n",
    "        \n",
    "    #     for i in range(num_batches):\n",
    "    #         # Lấy batch dữ liệu\n",
    "    #         val_batch = val_batches[i * config['batch_size'] : (i + 1) * config['batch_size']]  # (bs, ts_size, z_dim)\n",
    "            \n",
    "    #         x_ori = torch.tensor(val_batch, dtype=torch.float32).to(config['device'])\n",
    "    #         x_enc, x_dec = model(x_ori, pseudo_masks, 'ae')\n",
    "    #         loss = criterion(x_dec, x_ori)\n",
    "            \n",
    "    #         # Cộng dồn loss cho mỗi batch\n",
    "    #         val_loss += loss.item()\n",
    "        \n",
    "    #     # Tính trung bình của val_loss\n",
    "    #     if num_batches > 0:\n",
    "    #         val_loss /= num_batches\n",
    "    #     else:\n",
    "    #         val_loss = 1e9\n",
    "        \n",
    "    #     # ------------- END OF: Calculate loss on validation set: -----------------------\n",
    "        \n",
    "        \n",
    "    #     # Báo cáo loss trên tập validation cho Ray Tune\n",
    "    #     ray.train.report({'loss': val_loss})\n",
    "    \n",
    "    # ------------------- END OF: TRAIN AE ----------------------------\n",
    "    \n",
    "    \n",
    "    # ------------------- TRAIN EMBED ----------------------------\n",
    "    # for t in tqdm(range(config['epochs'])):\n",
    "    #     # ------------ Train model: -----------------\n",
    "    #     x_ori = get_mini_batch(batch_size=config['batch_size'], data=train_batches)  # (bs, ts_size, z_dim)\n",
    "        \n",
    "    #     x_ori = torch.tensor(x_ori, dtype=torch.float32).to(config['device'])\n",
    "    #     random_masks = generate_random_masks(num_samples=config['batch_size'], ts_size=model.config['ts_size'], mask_size=model.config['mask_size'], num_masks=model.config['num_masks'])\n",
    "\n",
    "    #     # Get the target x_ori_enc by Autoencoder\n",
    "    #     model.eval()\n",
    "    #     masks = pseudo_masks\n",
    "    #     x_ori_enc, _ = model(x_ori, pseudo_masks, 'ae')\n",
    "    #     x_ori_enc = x_ori_enc.clone().detach()  # (bs, ts_size, hidden_dim)\n",
    "    #     b, l, f = x_ori_enc.size()\n",
    "\n",
    "    #     model.train()\n",
    "    #     masks = random_masks\n",
    "    #     x_enc, x_inter, x_dec = model(x_ori, random_masks, 'mae')\n",
    "\n",
    "    #     # Only calculate loss for those being masked\n",
    "    #     x_enc_masked = x_enc[masks, :].reshape(b, -1, f)\n",
    "    #     x_ori_enc_masked = x_ori_enc[masks, :].reshape(b, -1, f)\n",
    "    #     loss = criterion(x_enc_masked, x_ori_enc_masked)\n",
    "    #     # By annotate lines above, we take loss on all patches\n",
    "    #     # loss = self.criterion(x_enc, x_ori_enc)  # embed_loss\n",
    "        \n",
    "    #     optimizer.zero_grad()\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()\n",
    "        \n",
    "    #     # -------------- END OF: Train model -----------------\n",
    "    #     # ------------- Calculate loss on validation set: -----------------------\n",
    "    #     model.eval()\n",
    "        \n",
    "    #     val_loss = 0\n",
    "        \n",
    "    #     num_batches = len(val_batches) // config['batch_size']\n",
    "        \n",
    "    #     for i in range(num_batches):\n",
    "    #         # Lấy batch dữ liệu\n",
    "    #         val_batch = val_batches[i * config['batch_size'] : (i + 1) * config['batch_size']]  # (bs, ts_size, z_dim)\n",
    "            \n",
    "    #         x_ori = torch.tensor(val_batch, dtype=torch.float32).to(config['device'])\n",
    "    #         random_masks = generate_random_masks(num_samples=config['batch_size'], ts_size=model.config['ts_size'], mask_size=model.config['mask_size'], num_masks=model.config['num_masks'])  # (bs, ts_size)\n",
    "            \n",
    "    #         # Get the target x_ori_enc by Autoencoder\n",
    "    #         masks = pseudo_masks\n",
    "    #         x_ori_enc, _ = model(x_ori, pseudo_masks, 'ae')\n",
    "    #         x_ori_enc = x_ori_enc.clone().detach()  # (bs, ts_size, hidden_dim)\n",
    "    #         b, l, f = x_ori_enc.size()\n",
    "            \n",
    "    #         masks = random_masks\n",
    "    #         x_enc, x_inter, x_dec = model(x_ori, random_masks, 'mae')\n",
    "\n",
    "    #         # Only calculate loss for those being masked\n",
    "    #         x_enc_masked = x_enc[masks, :].reshape(b, -1, f)\n",
    "    #         x_ori_enc_masked = x_ori_enc[masks, :].reshape(b, -1, f)\n",
    "    #         loss = criterion(x_enc_masked, x_ori_enc_masked)\n",
    "    #         # By annotate lines above, we take loss on all patches\n",
    "    #         # loss = self.criterion(x_enc, x_ori_enc)  # embed_loss\n",
    "            \n",
    "    #         # Cộng dồn loss cho mỗi batch\n",
    "    #         val_loss += loss.item()\n",
    "        \n",
    "    #     # Tính trung bình của val_loss\n",
    "    #     if num_batches > 0:\n",
    "    #         val_loss /= num_batches\n",
    "    #     else:\n",
    "    #         val_loss = 1e9\n",
    "        \n",
    "    #     # ------------- END OF: Calculate loss on validation set: -----------------------\n",
    "        \n",
    "    #     # Báo cáo loss trên tập validation cho Ray Tune\n",
    "    #     ray.train.report({'loss': val_loss})\n",
    "        \n",
    "    # ------------------- END OF: TRAIN EMBED ----------------------------\n",
    "    \n",
    "    \n",
    "    # ------------------- TRAIN RECON ----------------------------\n",
    "    for t in tqdm(range(config['epochs'])):\n",
    "        # ------------ Train model: -----------------\n",
    "        x_ori = get_mini_batch(batch_size=config['batch_size'], data=train_batches)  # (bs, ts_size, z_dim)\n",
    "        \n",
    "        x_ori = torch.tensor(x_ori, dtype=torch.float32).to(config['device'])\n",
    "        random_masks = generate_random_masks(num_samples=config['batch_size'], ts_size=model.config['ts_size'], mask_size=model.config['mask_size'], num_masks=model.config['num_masks'])  # (bs, ts_size)\n",
    "\n",
    "        model.train()\n",
    "        masks = random_masks\n",
    "        _, x_inter, x_dec = model(x_ori, random_masks, 'mae')\n",
    "        loss = criterion(x_dec, x_ori)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # -------------- END OF: Train model -----------------\n",
    "        # ------------- Calculate loss on validation set: -----------------------\n",
    "        model.eval()\n",
    "        \n",
    "        val_loss = 0\n",
    "        \n",
    "        num_batches = len(val_batches) // config['batch_size']\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            # Lấy batch dữ liệu\n",
    "            val_batch = val_batches[i * config['batch_size'] : (i + 1) * config['batch_size']]  # (bs, ts_size, z_dim)\n",
    "            \n",
    "            x_ori = torch.tensor(val_batch, dtype=torch.float32).to(config['device'])\n",
    "            random_masks = generate_random_masks(num_samples=config['batch_size'], ts_size=model.config['ts_size'], mask_size=model.config['mask_size'], num_masks=model.config['num_masks'])  # (bs, ts_size)\n",
    "            \n",
    "            masks = random_masks\n",
    "            _, x_inter, x_dec = model(x_ori, random_masks, 'mae')\n",
    "            loss = criterion(x_dec, x_ori)\n",
    "            \n",
    "            # Cộng dồn loss cho mỗi batch\n",
    "            val_loss += loss.item()\n",
    "        \n",
    "        # Tính trung bình của val_loss\n",
    "        if num_batches > 0:\n",
    "            val_loss /= num_batches\n",
    "        else:\n",
    "            val_loss = 1e9\n",
    "        \n",
    "        # ------------- END OF: Calculate loss on validation set: -----------------------\n",
    "        \n",
    "        #  Báo cáo loss trên tập validation cho Ray Tune\n",
    "        ray.train.report({'loss': val_loss})\n",
    "        \n",
    "    # ------------------- END OF: TRAIN RECON ----------------------------\n",
    "        \n",
    "        \n",
    "\n",
    "# Bước 3: Cấu hình hyperparameter tuning\n",
    "def main():\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",  # Sử dụng loss trên tập validation để đánh giá\n",
    "        mode=\"min\",\n",
    "        max_t=config['max_num_epochs'],\n",
    "        grace_period=config['grace_period'],\n",
    "        reduction_factor=config['reduction_factor']\n",
    "    )\n",
    "    \n",
    "    result = tune.run(\n",
    "        # train_model,\n",
    "        tune.with_parameters(trainable=train_model),\n",
    "        resources_per_trial={\"cpu\": 1, \"gpu\": config['gpus_per_trial']},\n",
    "        config=config,\n",
    "        num_samples=config['num_samples'],\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
    "    \n",
    "    return best_trial\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_trial = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretrained_model_dir': '/home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/models_saved/pretrained',\n",
       " 'stock_data_file': '/home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/Datasets/technology_ver_1.csv',\n",
       " 'batch_size': 16,\n",
       " 'split_ratio': 0.8,\n",
       " 'calculate_technical_indicators': False,\n",
       " 'lr': 0.00038170387616976386,\n",
       " 'optimizer': 'Adam',\n",
       " 'momentum': 0.8986611460040892,\n",
       " 'weight_decay': 0.00010469943492750553,\n",
       " 'scheduler': 'ReduceLROnPlateau',\n",
       " 'step_size': 10,\n",
       " 'gamma': 0.4436783435351249,\n",
       " 'num_samples': 20,\n",
       " 'epochs': 10,\n",
       " 'max_num_epochs': 100,\n",
       " 'gpus_per_trial': 0,\n",
       " 'grace_period': 1,\n",
       " 'reduction_factor': 2,\n",
       " 'device': 'cpu'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For: Create New Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import functional as F\n",
    "from einops import rearrange\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('/home/tiennv/FPT/FinanceTransformers')\n",
    "from logger_config import get_logger\n",
    "from stock_embedder import *\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import ta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Trainer\n",
    "    'stock_data_file': '/home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/Datasets/technology_ver_1.csv',\n",
    "    \"batch_size\": tune.choice([16, 32, 64, 128, 256]),\n",
    "    'split_ratio': 0.8,\n",
    "    'calculate_technical_indicators': True,\n",
    "    'rolling_window': 30,\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "    \"optimizer\": tune.choice([\"Adam\", \"SGD\"]),\n",
    "    \"momentum\": tune.uniform(0.8, 0.99),\n",
    "    \"weight_decay\": tune.loguniform(1e-5, 1e-3),\n",
    "    \"scheduler\": tune.choice([\"StepLR\", \"ReduceLROnPlateau\"]),\n",
    "    \"step_size\": tune.choice([5, 10, 20]),\n",
    "    \"gamma\": tune.uniform(0.1, 0.5),\n",
    "    # Model:\n",
    "    'ts_size': tune.choice([24, 60]),\n",
    "    'mask_size': tune.choice([1, 2]),\n",
    "    'num_masks': tune.choice([1, 2]),\n",
    "    'hidden_dim': tune.choice([12, 24]),\n",
    "    'embed_dim': tune.choice([6, 12, 18]),\n",
    "    'num_layer': tune.choice([2, 3, 4]),\n",
    "    'z_dim': 20,\n",
    "    'num_embed': tune.choice([32, 64]),\n",
    "    # Ray Tune:\n",
    "    'num_samples': 20,\n",
    "    'epochs': 10,\n",
    "    'max_num_epochs': 100,\n",
    "    'gpus_per_trial': 0,\n",
    "    'grace_period': 1,\n",
    "    'reduction_factor': 2,\n",
    "    'device': 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Giải thích:**\n",
    "\n",
    "`max_t=max_num_epochs`: Mỗi thử nghiệm có thể chạy tối đa max_num_epochs epoch.\n",
    "\n",
    "`grace_period=1`: Scheduler sẽ đợi ít nhất 1 epoch trước khi quyết định loại bỏ các thử nghiệm không tốt.\n",
    "\n",
    "`reduction_factor=2`: Sau mỗi giai đoạn, scheduler sẽ giảm số lượng thử nghiệm còn lại xuống một nửa, giúp tập trung vào những thử nghiệm hứa hẹn nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*# Bước 1*\n",
    "\n",
    "\n",
    "**Define Models Architecture and Data Loader**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Loader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, ratio):\n",
    "    idx = np.random.permutation(len(data))\n",
    "    train_idx = idx[:int(ratio * len(data))]\n",
    "    test_idx = idx[int(ratio * len(data)):]\n",
    "    train_data = data[train_idx, ...]\n",
    "    test_data = data[test_idx, ...]\n",
    "    return train_data, test_data\n",
    "\n",
    "def load_data(ts_size, data):\n",
    "    # data.shape = (rows, features)\n",
    "    \n",
    "    def sliding_window(ts_size, ori_data):\n",
    "        # Flipping the data to make chronological data\n",
    "        ori_data = ori_data[::-1]  # (len(csv), z_dim)\n",
    "        # Make (len(ori_data), z_dim) into (num_samples, seq_len, z_dim)\n",
    "        samples = []\n",
    "        for i in range(len(ori_data) - ts_size):\n",
    "            single_sample = ori_data[i:i + ts_size]  # (seq_len, z_dim)\n",
    "            samples.append(single_sample)\n",
    "        samples = np.array(samples)  # (bs, seq_len, z_dim)\n",
    "        np.random.shuffle(samples)  # Make it more like i.i.d.\n",
    "        return samples\n",
    "\n",
    "    data = sliding_window(ts_size=ts_size, ori_data=data)  # (bs, ts_size, z_dim)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_technical_indicators(df_passed: pd.DataFrame, rolling_window = 50):\n",
    "    df = df_passed.copy()\n",
    "    \n",
    "    def generate_indicators(df, rolling_window = 50):\n",
    "        # Calculate technical indicators\n",
    "        # df['momentum'] = ta.momentum.roc(df['Close'])\n",
    "        # df['trend'] = ta.trend.sma_indicator(df['Close'])\n",
    "        # df['volatility'] = ta.volatility.bollinger_mavg(df['Close'])\n",
    "        # df['volume'] = ta.volume.on_balance_volume(df['Close'], df['Volume'])\n",
    "        df['stoch'] = ta.momentum.stoch(df['High'], df['Low'], df['Close'])\n",
    "        df['adx'] = ta.trend.adx(df['High'], df['Low'], df['Close'])\n",
    "        df['bollinger_hband'] = ta.volatility.bollinger_hband(df['Close'])\n",
    "        df['mfi'] = ta.volume.money_flow_index(df['High'], df['Low'], df['Close'], df['Volume'])\n",
    "        df['rsi'] = ta.momentum.rsi(df['Close'])\n",
    "        df['ma'] = ta.trend.sma_indicator(df['Close'])\n",
    "        df['std'] = df['Close'].rolling(window=rolling_window).std()\n",
    "        df['adl'] = ta.volume.acc_dist_index(df['High'], df['Low'], df['Close'], df['Volume'])\n",
    "        df['williams'] = ta.momentum.williams_r(df['High'], df['Low'], df['Close'])\n",
    "        df['macd'] = ta.trend.macd(df['Close'])\n",
    "        df['obv'] = ta.volume.on_balance_volume(df['Close'], df['Volume'])\n",
    "        df['sar'] = ta.trend.psar_down(df['High'], df['Low'], df['Close']) # Added the 'close' argument\n",
    "        df['ichimoku_a'] = ta.trend.ichimoku_a(df['High'], df['Low'])\n",
    "        df['ichimoku_b'] = ta.trend.ichimoku_b(df['High'], df['Low'])\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df = generate_indicators(df=df, rolling_window=rolling_window)\n",
    "    \n",
    "    # Fillna\n",
    "    df = df.fillna(method='ffill')\n",
    "    df = df.iloc[rolling_window + 1 : ]\n",
    "    df = df.fillna(method='bfill')\n",
    "    \n",
    "    if df.isna().sum().sum() > 0:\n",
    "        raise Exception('NaN values found')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>JBL</td>\n",
       "      <td>14.340293</td>\n",
       "      <td>17.040001</td>\n",
       "      <td>17.620001</td>\n",
       "      <td>16.940001</td>\n",
       "      <td>17.610001</td>\n",
       "      <td>3682500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>FSLR</td>\n",
       "      <td>138.240005</td>\n",
       "      <td>138.240005</td>\n",
       "      <td>141.240005</td>\n",
       "      <td>137.770004</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>1575400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>FI</td>\n",
       "      <td>12.227500</td>\n",
       "      <td>12.227500</td>\n",
       "      <td>12.245000</td>\n",
       "      <td>12.125000</td>\n",
       "      <td>12.190000</td>\n",
       "      <td>5786000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>IT</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>20.309999</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>MCHP</td>\n",
       "      <td>9.767199</td>\n",
       "      <td>14.230000</td>\n",
       "      <td>14.285000</td>\n",
       "      <td>14.090000</td>\n",
       "      <td>14.245000</td>\n",
       "      <td>4489600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261364</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>ADI</td>\n",
       "      <td>199.815201</td>\n",
       "      <td>200.610001</td>\n",
       "      <td>204.199997</td>\n",
       "      <td>200.500000</td>\n",
       "      <td>203.630005</td>\n",
       "      <td>2668400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261365</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>169.240005</td>\n",
       "      <td>165.809998</td>\n",
       "      <td>169.229996</td>\n",
       "      <td>6914200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261366</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>INTU</td>\n",
       "      <td>625.619995</td>\n",
       "      <td>625.619995</td>\n",
       "      <td>637.919983</td>\n",
       "      <td>625.229980</td>\n",
       "      <td>637.010010</td>\n",
       "      <td>1309700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261367</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>FTV</td>\n",
       "      <td>75.188156</td>\n",
       "      <td>75.269997</td>\n",
       "      <td>77.105003</td>\n",
       "      <td>75.220001</td>\n",
       "      <td>77.010002</td>\n",
       "      <td>2356300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261368</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>IT</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>458.079987</td>\n",
       "      <td>411.149994</td>\n",
       "      <td>458.059998</td>\n",
       "      <td>1344200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261369 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Symbol   Adj Close       Close        High         Low  \\\n",
       "0       2010-01-11    JBL   14.340293   17.040001   17.620001   16.940001   \n",
       "1       2010-01-11   FSLR  138.240005  138.240005  141.240005  137.770004   \n",
       "2       2010-01-11     FI   12.227500   12.227500   12.245000   12.125000   \n",
       "3       2010-01-11     IT   20.600000   20.600000   20.690001   20.309999   \n",
       "4       2010-01-11   MCHP    9.767199   14.230000   14.285000   14.090000   \n",
       "...            ...    ...         ...         ...         ...         ...   \n",
       "261364  2024-04-30    ADI  199.815201  200.610001  204.199997  200.500000   \n",
       "261365  2024-04-30   QCOM  165.850006  165.850006  169.240005  165.809998   \n",
       "261366  2024-04-30   INTU  625.619995  625.619995  637.919983  625.229980   \n",
       "261367  2024-04-30    FTV   75.188156   75.269997   77.105003   75.220001   \n",
       "261368  2024-04-30     IT  412.589996  412.589996  458.079987  411.149994   \n",
       "\n",
       "              Open     Volume  \n",
       "0        17.610001  3682500.0  \n",
       "1       141.000000  1575400.0  \n",
       "2        12.190000  5786000.0  \n",
       "3        20.690001   386400.0  \n",
       "4        14.245000  4489600.0  \n",
       "...            ...        ...  \n",
       "261364  203.630005  2668400.0  \n",
       "261365  169.229996  6914200.0  \n",
       "261366  637.010010  1309700.0  \n",
       "261367   77.010002  2356300.0  \n",
       "261368  458.059998  1344200.0  \n",
       "\n",
       "[261369 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_symbols_df = pd.read_csv(config['stock_data_file'], encoding='UTF-8')\n",
    "all_symbols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>JBL</td>\n",
       "      <td>14.340293</td>\n",
       "      <td>17.040001</td>\n",
       "      <td>17.620001</td>\n",
       "      <td>16.940001</td>\n",
       "      <td>17.610001</td>\n",
       "      <td>3682500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>FSLR</td>\n",
       "      <td>138.240005</td>\n",
       "      <td>138.240005</td>\n",
       "      <td>141.240005</td>\n",
       "      <td>137.770004</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>1575400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>FI</td>\n",
       "      <td>12.227500</td>\n",
       "      <td>12.227500</td>\n",
       "      <td>12.245000</td>\n",
       "      <td>12.125000</td>\n",
       "      <td>12.190000</td>\n",
       "      <td>5786000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>IT</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>20.309999</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>MCHP</td>\n",
       "      <td>9.767199</td>\n",
       "      <td>14.230000</td>\n",
       "      <td>14.285000</td>\n",
       "      <td>14.090000</td>\n",
       "      <td>14.245000</td>\n",
       "      <td>4489600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261364</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>ADI</td>\n",
       "      <td>199.815201</td>\n",
       "      <td>200.610001</td>\n",
       "      <td>204.199997</td>\n",
       "      <td>200.500000</td>\n",
       "      <td>203.630005</td>\n",
       "      <td>2668400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261365</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>169.240005</td>\n",
       "      <td>165.809998</td>\n",
       "      <td>169.229996</td>\n",
       "      <td>6914200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261366</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>INTU</td>\n",
       "      <td>625.619995</td>\n",
       "      <td>625.619995</td>\n",
       "      <td>637.919983</td>\n",
       "      <td>625.229980</td>\n",
       "      <td>637.010010</td>\n",
       "      <td>1309700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261367</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>FTV</td>\n",
       "      <td>75.188156</td>\n",
       "      <td>75.269997</td>\n",
       "      <td>77.105003</td>\n",
       "      <td>75.220001</td>\n",
       "      <td>77.010002</td>\n",
       "      <td>2356300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261368</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>IT</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>458.079987</td>\n",
       "      <td>411.149994</td>\n",
       "      <td>458.059998</td>\n",
       "      <td>1344200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261369 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Symbol   Adj Close       Close        High         Low  \\\n",
       "0      2010-01-11    JBL   14.340293   17.040001   17.620001   16.940001   \n",
       "1      2010-01-11   FSLR  138.240005  138.240005  141.240005  137.770004   \n",
       "2      2010-01-11     FI   12.227500   12.227500   12.245000   12.125000   \n",
       "3      2010-01-11     IT   20.600000   20.600000   20.690001   20.309999   \n",
       "4      2010-01-11   MCHP    9.767199   14.230000   14.285000   14.090000   \n",
       "...           ...    ...         ...         ...         ...         ...   \n",
       "261364 2024-04-30    ADI  199.815201  200.610001  204.199997  200.500000   \n",
       "261365 2024-04-30   QCOM  165.850006  165.850006  169.240005  165.809998   \n",
       "261366 2024-04-30   INTU  625.619995  625.619995  637.919983  625.229980   \n",
       "261367 2024-04-30    FTV   75.188156   75.269997   77.105003   75.220001   \n",
       "261368 2024-04-30     IT  412.589996  412.589996  458.079987  411.149994   \n",
       "\n",
       "              Open     Volume  \n",
       "0        17.610001  3682500.0  \n",
       "1       141.000000  1575400.0  \n",
       "2        12.190000  5786000.0  \n",
       "3        20.690001   386400.0  \n",
       "4        14.245000  4489600.0  \n",
       "...            ...        ...  \n",
       "261364  203.630005  2668400.0  \n",
       "261365  169.229996  6914200.0  \n",
       "261366  637.010010  1309700.0  \n",
       "261367   77.010002  2356300.0  \n",
       "261368  458.059998  1344200.0  \n",
       "\n",
       "[261369 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_symbols_df['Date'] = pd.to_datetime(all_symbols_df['Date'])\n",
    "all_symbols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>JBL</td>\n",
       "      <td>14.340293</td>\n",
       "      <td>17.040001</td>\n",
       "      <td>17.620001</td>\n",
       "      <td>16.940001</td>\n",
       "      <td>17.610001</td>\n",
       "      <td>3682500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>ADSK</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>26.490000</td>\n",
       "      <td>26.070000</td>\n",
       "      <td>26.340000</td>\n",
       "      <td>2151300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>GRMN</td>\n",
       "      <td>21.318253</td>\n",
       "      <td>34.290001</td>\n",
       "      <td>34.450001</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>34.099998</td>\n",
       "      <td>1997700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>APH</td>\n",
       "      <td>5.031209</td>\n",
       "      <td>5.661250</td>\n",
       "      <td>5.692500</td>\n",
       "      <td>5.575000</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>6540800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>GLW</td>\n",
       "      <td>14.353989</td>\n",
       "      <td>20.490000</td>\n",
       "      <td>20.850000</td>\n",
       "      <td>20.219999</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>25617100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261313</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>170.099289</td>\n",
       "      <td>170.330002</td>\n",
       "      <td>174.990005</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>173.330002</td>\n",
       "      <td>65934800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261312</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>ENPH</td>\n",
       "      <td>108.760002</td>\n",
       "      <td>108.760002</td>\n",
       "      <td>111.949997</td>\n",
       "      <td>108.690002</td>\n",
       "      <td>111.250000</td>\n",
       "      <td>2768300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261311</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>MSI</td>\n",
       "      <td>339.149994</td>\n",
       "      <td>339.149994</td>\n",
       "      <td>347.070007</td>\n",
       "      <td>338.540009</td>\n",
       "      <td>346.700012</td>\n",
       "      <td>1220800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261318</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>APH</td>\n",
       "      <td>60.288956</td>\n",
       "      <td>60.384998</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>60.349998</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>7167200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261368</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>IT</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>412.589996</td>\n",
       "      <td>458.079987</td>\n",
       "      <td>411.149994</td>\n",
       "      <td>458.059998</td>\n",
       "      <td>1344200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261369 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Symbol   Adj Close       Close        High         Low  \\\n",
       "0      2010-01-11    JBL   14.340293   17.040001   17.620001   16.940001   \n",
       "33     2010-01-11   ADSK   26.250000   26.250000   26.490000   26.070000   \n",
       "34     2010-01-11   GRMN   21.318253   34.290001   34.450001   33.520000   \n",
       "35     2010-01-11    APH    5.031209    5.661250    5.692500    5.575000   \n",
       "36     2010-01-11    GLW   14.353989   20.490000   20.850000   20.219999   \n",
       "...           ...    ...         ...         ...         ...         ...   \n",
       "261313 2024-04-30   AAPL  170.099289  170.330002  174.990005  170.000000   \n",
       "261312 2024-04-30   ENPH  108.760002  108.760002  111.949997  108.690002   \n",
       "261311 2024-04-30    MSI  339.149994  339.149994  347.070007  338.540009   \n",
       "261318 2024-04-30    APH   60.288956   60.384998   61.799999   60.349998   \n",
       "261368 2024-04-30     IT  412.589996  412.589996  458.079987  411.149994   \n",
       "\n",
       "              Open      Volume  \n",
       "0        17.610001   3682500.0  \n",
       "33       26.340000   2151300.0  \n",
       "34       34.099998   1997700.0  \n",
       "35        5.680000   6540800.0  \n",
       "36       20.620001  25617100.0  \n",
       "...            ...         ...  \n",
       "261313  173.330002  65934800.0  \n",
       "261312  111.250000   2768300.0  \n",
       "261311  346.700012   1220800.0  \n",
       "261318   61.000000   7167200.0  \n",
       "261368  458.059998   1344200.0  \n",
       "\n",
       "[261369 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_symbols_df = all_symbols_df.sort_values(by='Date')\n",
    "all_symbols_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Choose Dates Range*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82033</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>TER</td>\n",
       "      <td>18.421520</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.469999</td>\n",
       "      <td>19.920000</td>\n",
       "      <td>1030300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82039</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>LRCX</td>\n",
       "      <td>69.079231</td>\n",
       "      <td>79.449997</td>\n",
       "      <td>80.190002</td>\n",
       "      <td>78.839996</td>\n",
       "      <td>79.870003</td>\n",
       "      <td>830600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82038</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ADI</td>\n",
       "      <td>45.454937</td>\n",
       "      <td>55.540001</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>54.970001</td>\n",
       "      <td>55.680000</td>\n",
       "      <td>1323200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82037</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>MSI</td>\n",
       "      <td>58.383911</td>\n",
       "      <td>66.510002</td>\n",
       "      <td>67.730003</td>\n",
       "      <td>66.360001</td>\n",
       "      <td>67.540001</td>\n",
       "      <td>1077900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82036</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>CDW</td>\n",
       "      <td>31.416943</td>\n",
       "      <td>34.860001</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>34.599998</td>\n",
       "      <td>35.259998</td>\n",
       "      <td>380200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100323</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>17.243118</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>18.959999</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>18.940001</td>\n",
       "      <td>8685100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100322</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>NXPI</td>\n",
       "      <td>76.961082</td>\n",
       "      <td>84.250000</td>\n",
       "      <td>85.870003</td>\n",
       "      <td>84.150002</td>\n",
       "      <td>85.430000</td>\n",
       "      <td>2140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100321</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>MCHP</td>\n",
       "      <td>20.020269</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>23.924999</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>23.825001</td>\n",
       "      <td>2316200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100320</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>JBL</td>\n",
       "      <td>21.590118</td>\n",
       "      <td>23.290001</td>\n",
       "      <td>23.629999</td>\n",
       "      <td>23.290001</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>1559900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100327</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>TXN</td>\n",
       "      <td>47.133926</td>\n",
       "      <td>54.810001</td>\n",
       "      <td>56.299999</td>\n",
       "      <td>54.810001</td>\n",
       "      <td>56.049999</td>\n",
       "      <td>6450100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18388 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Symbol  Adj Close      Close       High        Low  \\\n",
       "82033  2015-01-02    TER  18.421520  19.700001  20.000000  19.469999   \n",
       "82039  2015-01-02   LRCX  69.079231  79.449997  80.190002  78.839996   \n",
       "82038  2015-01-02    ADI  45.454937  55.540001  56.250000  54.970001   \n",
       "82037  2015-01-02    MSI  58.383911  66.510002  67.730003  66.360001   \n",
       "82036  2015-01-02    CDW  31.416943  34.860001  35.299999  34.599998   \n",
       "...           ...    ...        ...        ...        ...        ...   \n",
       "100323 2015-12-31   AMAT  17.243118  18.670000  18.959999  18.670000   \n",
       "100322 2015-12-31   NXPI  76.961082  84.250000  85.870003  84.150002   \n",
       "100321 2015-12-31   MCHP  20.020269  23.270000  23.924999  23.270000   \n",
       "100320 2015-12-31    JBL  21.590118  23.290001  23.629999  23.290001   \n",
       "100327 2015-12-31    TXN  47.133926  54.810001  56.299999  54.810001   \n",
       "\n",
       "             Open     Volume  \n",
       "82033   19.920000  1030300.0  \n",
       "82039   79.870003   830600.0  \n",
       "82038   55.680000  1323200.0  \n",
       "82037   67.540001  1077900.0  \n",
       "82036   35.259998   380200.0  \n",
       "...           ...        ...  \n",
       "100323  18.940001  8685100.0  \n",
       "100322  85.430000  2140000.0  \n",
       "100321  23.825001  2316200.0  \n",
       "100320  23.500000  1559900.0  \n",
       "100327  56.049999  6450100.0  \n",
       "\n",
       "[18388 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = '2015-01-01'\n",
    "end_date = '2016-01-01'\n",
    "\n",
    "all_symbols_df = all_symbols_df[(all_symbols_df['Date'] >= start_date) & (all_symbols_df['Date'] <= end_date)]\n",
    "all_symbols_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Get min_val, max_val*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2867438/2644189174.py:30: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill')\n",
      "/tmp/ipykernel_2867438/2644189174.py:32: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='bfill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>stoch</th>\n",
       "      <th>adx</th>\n",
       "      <th>...</th>\n",
       "      <th>rsi</th>\n",
       "      <th>ma</th>\n",
       "      <th>std</th>\n",
       "      <th>adl</th>\n",
       "      <th>williams</th>\n",
       "      <th>macd</th>\n",
       "      <th>obv</th>\n",
       "      <th>sar</th>\n",
       "      <th>ichimoku_a</th>\n",
       "      <th>ichimoku_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82045</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>CRM</td>\n",
       "      <td>59.070766</td>\n",
       "      <td>59.240002</td>\n",
       "      <td>60.430000</td>\n",
       "      <td>58.509998</td>\n",
       "      <td>59.900002</td>\n",
       "      <td>2796400.0</td>\n",
       "      <td>33.403506</td>\n",
       "      <td>8.275422</td>\n",
       "      <td>...</td>\n",
       "      <td>50.364198</td>\n",
       "      <td>61.096040</td>\n",
       "      <td>39.180109</td>\n",
       "      <td>-1.432365e+07</td>\n",
       "      <td>-66.596494</td>\n",
       "      <td>6.571785</td>\n",
       "      <td>-1.753669e+08</td>\n",
       "      <td>137.689115</td>\n",
       "      <td>83.082499</td>\n",
       "      <td>79.989999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82044</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>INTC</td>\n",
       "      <td>28.073418</td>\n",
       "      <td>36.360001</td>\n",
       "      <td>37.160000</td>\n",
       "      <td>36.110001</td>\n",
       "      <td>36.669998</td>\n",
       "      <td>23605600.0</td>\n",
       "      <td>15.855017</td>\n",
       "      <td>7.781564</td>\n",
       "      <td>...</td>\n",
       "      <td>48.396385</td>\n",
       "      <td>61.993540</td>\n",
       "      <td>39.335916</td>\n",
       "      <td>-2.668848e+07</td>\n",
       "      <td>-84.144983</td>\n",
       "      <td>4.027497</td>\n",
       "      <td>-1.989725e+08</td>\n",
       "      <td>137.689115</td>\n",
       "      <td>83.082499</td>\n",
       "      <td>79.989999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82042</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>20.481958</td>\n",
       "      <td>27.610001</td>\n",
       "      <td>28.120001</td>\n",
       "      <td>27.379999</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>22926500.0</td>\n",
       "      <td>8.835314</td>\n",
       "      <td>7.428013</td>\n",
       "      <td>...</td>\n",
       "      <td>47.629944</td>\n",
       "      <td>61.398540</td>\n",
       "      <td>39.579674</td>\n",
       "      <td>-3.536331e+07</td>\n",
       "      <td>-91.164686</td>\n",
       "      <td>1.290205</td>\n",
       "      <td>-2.218990e+08</td>\n",
       "      <td>137.689115</td>\n",
       "      <td>83.082499</td>\n",
       "      <td>79.989999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82023</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>TRMB</td>\n",
       "      <td>26.910000</td>\n",
       "      <td>26.910000</td>\n",
       "      <td>26.959999</td>\n",
       "      <td>26.360001</td>\n",
       "      <td>26.700001</td>\n",
       "      <td>1106000.0</td>\n",
       "      <td>8.343291</td>\n",
       "      <td>7.112710</td>\n",
       "      <td>...</td>\n",
       "      <td>47.565047</td>\n",
       "      <td>51.119374</td>\n",
       "      <td>39.735654</td>\n",
       "      <td>-3.444164e+07</td>\n",
       "      <td>-91.656709</td>\n",
       "      <td>-0.924940</td>\n",
       "      <td>-2.230050e+08</td>\n",
       "      <td>157.309998</td>\n",
       "      <td>83.082499</td>\n",
       "      <td>79.989999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82032</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>ZBRA</td>\n",
       "      <td>77.430000</td>\n",
       "      <td>77.430000</td>\n",
       "      <td>78.419998</td>\n",
       "      <td>76.059998</td>\n",
       "      <td>77.989998</td>\n",
       "      <td>411800.0</td>\n",
       "      <td>43.853238</td>\n",
       "      <td>7.068758</td>\n",
       "      <td>...</td>\n",
       "      <td>52.586194</td>\n",
       "      <td>54.786874</td>\n",
       "      <td>39.896284</td>\n",
       "      <td>-3.437534e+07</td>\n",
       "      <td>-56.146762</td>\n",
       "      <td>1.380173</td>\n",
       "      <td>-2.225932e+08</td>\n",
       "      <td>154.690998</td>\n",
       "      <td>85.912499</td>\n",
       "      <td>79.989999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100323</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>17.243118</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>18.959999</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>18.940001</td>\n",
       "      <td>8685100.0</td>\n",
       "      <td>12.401151</td>\n",
       "      <td>6.391875</td>\n",
       "      <td>...</td>\n",
       "      <td>46.982974</td>\n",
       "      <td>54.133166</td>\n",
       "      <td>35.338450</td>\n",
       "      <td>5.348407e+09</td>\n",
       "      <td>-87.598849</td>\n",
       "      <td>2.842122</td>\n",
       "      <td>-1.239740e+11</td>\n",
       "      <td>98.449997</td>\n",
       "      <td>72.776998</td>\n",
       "      <td>72.776998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100322</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>NXPI</td>\n",
       "      <td>76.961082</td>\n",
       "      <td>84.250000</td>\n",
       "      <td>85.870003</td>\n",
       "      <td>84.150002</td>\n",
       "      <td>85.430000</td>\n",
       "      <td>2140000.0</td>\n",
       "      <td>57.972567</td>\n",
       "      <td>6.299500</td>\n",
       "      <td>...</td>\n",
       "      <td>52.080422</td>\n",
       "      <td>60.634499</td>\n",
       "      <td>35.650583</td>\n",
       "      <td>5.346516e+09</td>\n",
       "      <td>-42.027433</td>\n",
       "      <td>4.661001</td>\n",
       "      <td>-1.239719e+11</td>\n",
       "      <td>98.449997</td>\n",
       "      <td>72.776998</td>\n",
       "      <td>72.776998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100321</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>MCHP</td>\n",
       "      <td>20.020269</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>23.924999</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>23.825001</td>\n",
       "      <td>2316200.0</td>\n",
       "      <td>15.597683</td>\n",
       "      <td>6.139756</td>\n",
       "      <td>...</td>\n",
       "      <td>47.506477</td>\n",
       "      <td>54.493666</td>\n",
       "      <td>36.123059</td>\n",
       "      <td>5.344200e+09</td>\n",
       "      <td>-84.402317</td>\n",
       "      <td>1.168431</td>\n",
       "      <td>-1.239742e+11</td>\n",
       "      <td>98.449997</td>\n",
       "      <td>72.776998</td>\n",
       "      <td>72.776998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100320</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>JBL</td>\n",
       "      <td>21.590118</td>\n",
       "      <td>23.290001</td>\n",
       "      <td>23.629999</td>\n",
       "      <td>23.290001</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>1559900.0</td>\n",
       "      <td>15.611581</td>\n",
       "      <td>5.991423</td>\n",
       "      <td>...</td>\n",
       "      <td>47.508105</td>\n",
       "      <td>51.957000</td>\n",
       "      <td>36.443454</td>\n",
       "      <td>5.342640e+09</td>\n",
       "      <td>-84.388419</td>\n",
       "      <td>-1.579634</td>\n",
       "      <td>-1.239726e+11</td>\n",
       "      <td>144.729996</td>\n",
       "      <td>72.776998</td>\n",
       "      <td>72.776998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100327</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>TXN</td>\n",
       "      <td>47.133926</td>\n",
       "      <td>54.810001</td>\n",
       "      <td>56.299999</td>\n",
       "      <td>54.810001</td>\n",
       "      <td>56.049999</td>\n",
       "      <td>6450100.0</td>\n",
       "      <td>37.514769</td>\n",
       "      <td>5.655757</td>\n",
       "      <td>...</td>\n",
       "      <td>50.133416</td>\n",
       "      <td>54.313666</td>\n",
       "      <td>36.298479</td>\n",
       "      <td>5.336190e+09</td>\n",
       "      <td>-62.485231</td>\n",
       "      <td>-1.200258</td>\n",
       "      <td>-1.239662e+11</td>\n",
       "      <td>142.301196</td>\n",
       "      <td>72.776998</td>\n",
       "      <td>72.776998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18357 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Symbol  Adj Close      Close       High        Low  \\\n",
       "82045  2015-01-02    CRM  59.070766  59.240002  60.430000  58.509998   \n",
       "82044  2015-01-02   INTC  28.073418  36.360001  37.160000  36.110001   \n",
       "82042  2015-01-02   CSCO  20.481958  27.610001  28.120001  27.379999   \n",
       "82023  2015-01-02   TRMB  26.910000  26.910000  26.959999  26.360001   \n",
       "82032  2015-01-02   ZBRA  77.430000  77.430000  78.419998  76.059998   \n",
       "...           ...    ...        ...        ...        ...        ...   \n",
       "100323 2015-12-31   AMAT  17.243118  18.670000  18.959999  18.670000   \n",
       "100322 2015-12-31   NXPI  76.961082  84.250000  85.870003  84.150002   \n",
       "100321 2015-12-31   MCHP  20.020269  23.270000  23.924999  23.270000   \n",
       "100320 2015-12-31    JBL  21.590118  23.290001  23.629999  23.290001   \n",
       "100327 2015-12-31    TXN  47.133926  54.810001  56.299999  54.810001   \n",
       "\n",
       "             Open      Volume      stoch       adx  ...        rsi         ma  \\\n",
       "82045   59.900002   2796400.0  33.403506  8.275422  ...  50.364198  61.096040   \n",
       "82044   36.669998  23605600.0  15.855017  7.781564  ...  48.396385  61.993540   \n",
       "82042   27.860001  22926500.0   8.835314  7.428013  ...  47.629944  61.398540   \n",
       "82023   26.700001   1106000.0   8.343291  7.112710  ...  47.565047  51.119374   \n",
       "82032   77.989998    411800.0  43.853238  7.068758  ...  52.586194  54.786874   \n",
       "...           ...         ...        ...       ...  ...        ...        ...   \n",
       "100323  18.940001   8685100.0  12.401151  6.391875  ...  46.982974  54.133166   \n",
       "100322  85.430000   2140000.0  57.972567  6.299500  ...  52.080422  60.634499   \n",
       "100321  23.825001   2316200.0  15.597683  6.139756  ...  47.506477  54.493666   \n",
       "100320  23.500000   1559900.0  15.611581  5.991423  ...  47.508105  51.957000   \n",
       "100327  56.049999   6450100.0  37.514769  5.655757  ...  50.133416  54.313666   \n",
       "\n",
       "              std           adl   williams      macd           obv  \\\n",
       "82045   39.180109 -1.432365e+07 -66.596494  6.571785 -1.753669e+08   \n",
       "82044   39.335916 -2.668848e+07 -84.144983  4.027497 -1.989725e+08   \n",
       "82042   39.579674 -3.536331e+07 -91.164686  1.290205 -2.218990e+08   \n",
       "82023   39.735654 -3.444164e+07 -91.656709 -0.924940 -2.230050e+08   \n",
       "82032   39.896284 -3.437534e+07 -56.146762  1.380173 -2.225932e+08   \n",
       "...           ...           ...        ...       ...           ...   \n",
       "100323  35.338450  5.348407e+09 -87.598849  2.842122 -1.239740e+11   \n",
       "100322  35.650583  5.346516e+09 -42.027433  4.661001 -1.239719e+11   \n",
       "100321  36.123059  5.344200e+09 -84.402317  1.168431 -1.239742e+11   \n",
       "100320  36.443454  5.342640e+09 -84.388419 -1.579634 -1.239726e+11   \n",
       "100327  36.298479  5.336190e+09 -62.485231 -1.200258 -1.239662e+11   \n",
       "\n",
       "               sar  ichimoku_a  ichimoku_b  \n",
       "82045   137.689115   83.082499   79.989999  \n",
       "82044   137.689115   83.082499   79.989999  \n",
       "82042   137.689115   83.082499   79.989999  \n",
       "82023   157.309998   83.082499   79.989999  \n",
       "82032   154.690998   85.912499   79.989999  \n",
       "...            ...         ...         ...  \n",
       "100323   98.449997   72.776998   72.776998  \n",
       "100322   98.449997   72.776998   72.776998  \n",
       "100321   98.449997   72.776998   72.776998  \n",
       "100320  144.729996   72.776998   72.776998  \n",
       "100327  142.301196   72.776998   72.776998  \n",
       "\n",
       "[18357 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config['calculate_technical_indicators']:\n",
    "    all_symbols_df = calculate_technical_indicators(all_symbols_df, rolling_window=config['rolling_window'])\n",
    "\n",
    "all_symbols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.59453315e-01  4.78500009e-01  4.87500012e-01  4.73500013e-01\n",
      "  4.81249988e-01  0.00000000e+00  0.00000000e+00  3.21805341e+00\n",
      "  7.38272562e+01  1.73447777e+00  4.23946742e+01  2.48179424e+01\n",
      "  2.15548392e+01 -2.17302467e+09 -1.00000000e+02 -1.33643311e+01\n",
      " -1.23974206e+11  4.64983580e+01  3.42043750e+01  4.47023738e+01]\n",
      "[ 1.85039658e+02  1.94830002e+02  1.95929993e+02  1.93380005e+02\n",
      "  1.95000000e+02  1.40524800e+09  1.00000000e+02  9.20426719e+00\n",
      "  1.82642077e+02  9.92617096e+01  6.50187234e+01  1.00782710e+02\n",
      "  5.47552574e+01  7.10742327e+09 -0.00000000e+00  2.47550200e+01\n",
      " -6.81279730e+07  1.95929993e+02  1.13479998e+02  1.01789998e+02]\n"
     ]
    }
   ],
   "source": [
    "stock_features = [column for column in all_symbols_df.columns if column not in ['Date', 'Symbol']]\n",
    "\n",
    "min_val = all_symbols_df[stock_features].min().values\n",
    "max_val = all_symbols_df[stock_features].max().values\n",
    "\n",
    "config['stock_features'] = stock_features\n",
    "config['z_dim'] = len(stock_features)\n",
    "config['min_val'] = min_val\n",
    "config['max_val'] = max_val\n",
    "\n",
    "print(min_val)\n",
    "print(max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create Training and Validation Batches*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(config):\n",
    "    train_batches = torch.tensor(data=[])\n",
    "    val_batches = torch.tensor(data=[])\n",
    "\n",
    "    symbols = all_symbols_df['Symbol'].unique()\n",
    "\n",
    "    for symbol in tqdm(symbols):\n",
    "        df = all_symbols_df[all_symbols_df['Symbol'] == symbol]\n",
    "        df = df.sort_values(by='Date')\n",
    "        \n",
    "        if config['calculate_technical_indicators']:\n",
    "            df = calculate_technical_indicators(df, rolling_window=config['rolling_window'])\n",
    "        \n",
    "        df = df[config['stock_features']]\n",
    "        data = df.values\n",
    "        \n",
    "        train_data, val_data = train_test_split(data=data, ratio=config['split_ratio'])\n",
    "        \n",
    "        # Create batches (sliding window)\n",
    "        train_data = load_data(ts_size=config['ts_size'], data=train_data)\n",
    "        val_data = load_data(ts_size=config['ts_size'], data=val_data)\n",
    "        \n",
    "        if len(train_data) > 0:\n",
    "            train_data = normalize(train_data, min_val=config['min_val'], max_val=config['max_val'])\n",
    "            train_data = torch.tensor(train_data)\n",
    "            train_batches = torch.cat(tensors=[train_batches, train_data])\n",
    "        \n",
    "        if len(val_data) > 0:\n",
    "            val_data = normalize(val_data, min_val=config['min_val'], max_val=config['max_val'])\n",
    "            val_data = torch.tensor(val_data)\n",
    "            val_batches = torch.cat(tensors=[val_batches, val_data])\n",
    "            \n",
    "    \n",
    "    return train_batches, val_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Models Architecture*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mini_batch(batch_size, data):\n",
    "    idx = np.random.permutation(len(data))\n",
    "    idx = idx[:batch_size]\n",
    "    data_mini = data[idx, ...]  # (bs, seq_len, z_dim)\n",
    "    return data_mini\n",
    "\n",
    "def generate_random_masks(num_samples, ts_size, mask_size, num_masks):\n",
    "    # xxxo\n",
    "    # oxxx\n",
    "    # xxox\n",
    "    num_patches = int(ts_size // mask_size)\n",
    "\n",
    "    def single_sample_mask():\n",
    "        idx = np.random.permutation(num_patches)[:num_masks]\n",
    "        mask = np.zeros(ts_size, dtype=bool)\n",
    "        for j in idx:\n",
    "            mask[j * mask_size:(j + 1) * mask_size] = 1\n",
    "        return mask\n",
    "\n",
    "    masks_list = [single_sample_mask() for _ in range(num_samples)]\n",
    "    masks_list = [torch.tensor(mask) for mask in masks_list]\n",
    "    masks = torch.stack(masks_list, axis=0)  # (num_samples, ts_size)\n",
    "    return masks\n",
    "\n",
    "def generate_pseudo_masks(ts_size, num_samples):\n",
    "    # xxxx\n",
    "    # xxxx\n",
    "    # xxxx\n",
    "    masks = np.zeros((num_samples, ts_size), dtype=bool)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ray Tune**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 22:01:55,969\tINFO worker.py:1786 -- Started a local Ray instance.\n",
      "2024-09-22 22:01:56,982\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-09-22 22:01:56,984\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-09-22 22:02:20</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:22.95        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.4/62.6 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=12<br>Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: -1000000000.0 | Iter 4.000: -1000000000.0 | Iter 2.000: -1000000000.0 | Iter 1.000: -1.8204413917839424e+16<br>Logical resource usage: 1.0/24 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  embed_dim</th><th style=\"text-align: right;\">   gamma</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  mask_size</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">  num_embed</th><th style=\"text-align: right;\">  num_layer</th><th style=\"text-align: right;\">  num_masks</th><th>optimizer  </th><th>scheduler        </th><th style=\"text-align: right;\">  step_size</th><th style=\"text-align: right;\">  ts_size</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">       loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_9c899_00000</td><td>TERMINATED</td><td>192.168.2.115:2875302</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">0.457633</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">0.00719801 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">  0.877649</td><td style=\"text-align: right;\">         64</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          2</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">       60</td><td style=\"text-align: right;\">   4.94267e-05</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         14.5636</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00001</td><td>TERMINATED</td><td>192.168.2.115:2875303</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">0.294301</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">0.000619912</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">  0.975541</td><td style=\"text-align: right;\">         64</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">          2</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   0.000450539</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.725 </td><td style=\"text-align: right;\">1.88365e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00002</td><td>TERMINATED</td><td>192.168.2.115:2875304</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">0.370728</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">0.00250421 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">  0.857546</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">          1</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">       60</td><td style=\"text-align: right;\">   2.90297e-05</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         13.6344</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00003</td><td>TERMINATED</td><td>192.168.2.115:2875307</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">0.180369</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">0.000803313</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">  0.843203</td><td style=\"text-align: right;\">         64</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          2</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">       60</td><td style=\"text-align: right;\">   1.58034e-05</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         14.5352</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00004</td><td>TERMINATED</td><td>192.168.2.115:2875309</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">0.17396 </td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">0.00117239 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">  0.954146</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          2</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   0.000518312</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.9768</td><td style=\"text-align: right;\">1.87191e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00005</td><td>TERMINATED</td><td>192.168.2.115:2875308</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">         18</td><td style=\"text-align: right;\">0.374203</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">0.00296235 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">  0.838773</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          1</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   3.51074e-05</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         12.7858</td><td style=\"text-align: right;\">1.83271e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00006</td><td>TERMINATED</td><td>192.168.2.115:2875310</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">         18</td><td style=\"text-align: right;\">0.467479</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">0.0081818  </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">  0.827437</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">          1</td><td>SGD        </td><td>StepLR           </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   3.3139e-05 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         14.3509</td><td style=\"text-align: right;\">1.3062e+16 </td></tr>\n",
       "<tr><td>train_model_9c899_00007</td><td>TERMINATED</td><td>192.168.2.115:2875311</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">0.412069</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">0.00965453 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">  0.800118</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">          2</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   0.000732101</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.5415</td><td style=\"text-align: right;\">1.85775e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00008</td><td>TERMINATED</td><td>192.168.2.115:2875313</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">0.363492</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">0.000130471</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">  0.846465</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          2</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   4.22666e-05</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         12.8614</td><td style=\"text-align: right;\">1.84786e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00009</td><td>TERMINATED</td><td>192.168.2.115:2875315</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">0.222401</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">0.000397912</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">  0.890696</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          1</td><td>SGD        </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   2.24808e-05</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         12.9012</td><td style=\"text-align: right;\">1.82612e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00010</td><td>TERMINATED</td><td>192.168.2.115:2875316</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">0.324253</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">0.00271114 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">  0.805865</td><td style=\"text-align: right;\">         64</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          2</td><td>SGD        </td><td>StepLR           </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   0.000804058</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.3658</td><td style=\"text-align: right;\">1.9034e+16 </td></tr>\n",
       "<tr><td>train_model_9c899_00011</td><td>TERMINATED</td><td>192.168.2.115:2875317</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">         18</td><td style=\"text-align: right;\">0.24746 </td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">0.000359606</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">  0.90428 </td><td style=\"text-align: right;\">         64</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">          1</td><td>SGD        </td><td>StepLR           </td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">       60</td><td style=\"text-align: right;\">   0.000640137</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         13.1082</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00012</td><td>TERMINATED</td><td>192.168.2.115:2875318</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">0.462558</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">0.00301593 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">  0.928789</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          1</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   0.000706112</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         14.8117</td><td style=\"text-align: right;\">1.79605e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00013</td><td>TERMINATED</td><td>192.168.2.115:2875319</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">0.283477</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">0.00408286 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">  0.874229</td><td style=\"text-align: right;\">         64</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">          1</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">       60</td><td style=\"text-align: right;\">   0.000381483</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         15.0148</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00014</td><td>TERMINATED</td><td>192.168.2.115:2875321</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">0.368502</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">0.00903295 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">  0.816535</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">          1</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">       60</td><td style=\"text-align: right;\">   8.19883e-05</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         14.2977</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00015</td><td>TERMINATED</td><td>192.168.2.115:2875320</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">0.299787</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">0.000513619</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">  0.848731</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          1</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">       60</td><td style=\"text-align: right;\">   0.000208947</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         13.9805</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00016</td><td>TERMINATED</td><td>192.168.2.115:2875326</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         18</td><td style=\"text-align: right;\">0.369612</td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">0.00241358 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">  0.888316</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">          2</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   1.51311e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.8808</td><td style=\"text-align: right;\">1.87981e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00017</td><td>TERMINATED</td><td>192.168.2.115:2875325</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">0.423476</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">0.00549695 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">  0.924958</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">          1</td><td>Adam       </td><td>ReduceLROnPlateau</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">       60</td><td style=\"text-align: right;\">   0.000247553</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         14.4667</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00018</td><td>TERMINATED</td><td>192.168.2.115:2875324</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">0.190943</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">0.00284091 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">  0.952299</td><td style=\"text-align: right;\">         64</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">          1</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   0.000516199</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         12.2703</td><td style=\"text-align: right;\">1.81605e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00019</td><td>TERMINATED</td><td>192.168.2.115:2875327</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">0.272322</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">0.000129481</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">  0.832448</td><td style=\"text-align: right;\">         32</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">          2</td><td>Adam       </td><td>StepLR           </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">       24</td><td style=\"text-align: right;\">   0.000376086</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         12.7352</td><td style=\"text-align: right;\">1.82527e+16</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=2875302)\u001b[0m   0%|          | 0/74 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=2875302)\u001b[0m /tmp/ipykernel_2867438/2644189174.py:30: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "\u001b[36m(train_model pid=2875302)\u001b[0m /tmp/ipykernel_2867438/2644189174.py:32: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "\u001b[36m(train_model pid=2875302)\u001b[0m /tmp/ipykernel_2867438/2644189174.py:30: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "\u001b[36m(train_model pid=2875302)\u001b[0m /tmp/ipykernel_2867438/2644189174.py:32: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "\u001b[36m(train_model pid=2875316)\u001b[0m /tmp/ipykernel_2867438/2644189174.py:32: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\u001b[32m [repeated 1400x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_model pid=2875316)\u001b[0m /tmp/ipykernel_2867438/2644189174.py:32: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\u001b[32m [repeated 1300x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=2875303)\u001b[0m /tmp/ipykernel_2867438/330319707.py:168: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[36m(train_model pid=2875303)\u001b[0m /home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/stock_embedder.py:139: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[36m(train_model pid=2875303)\u001b[0m   x = torch.tensor(x, dtype=torch.float32)\n",
      "\u001b[36m(train_model pid=2875303)\u001b[0m /home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/stock_embedder.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[36m(train_model pid=2875303)\u001b[0m   masks = torch.tensor(masks, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=2875303)\u001b[0m   0%|          | 0/10 [00:00<?, ?it/s]\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">       loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_9c899_00000</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00001</td><td style=\"text-align: right;\">1.88365e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00002</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00003</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00004</td><td style=\"text-align: right;\">1.87191e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00005</td><td style=\"text-align: right;\">1.83271e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00006</td><td style=\"text-align: right;\">1.3062e+16 </td></tr>\n",
       "<tr><td>train_model_9c899_00007</td><td style=\"text-align: right;\">1.85775e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00008</td><td style=\"text-align: right;\">1.84786e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00009</td><td style=\"text-align: right;\">1.82612e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00010</td><td style=\"text-align: right;\">1.9034e+16 </td></tr>\n",
       "<tr><td>train_model_9c899_00011</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00012</td><td style=\"text-align: right;\">1.79605e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00013</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00014</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00015</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00016</td><td style=\"text-align: right;\">1.87981e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00017</td><td style=\"text-align: right;\">1e+09      </td></tr>\n",
       "<tr><td>train_model_9c899_00018</td><td style=\"text-align: right;\">1.81605e+16</td></tr>\n",
       "<tr><td>train_model_9c899_00019</td><td style=\"text-align: right;\">1.82527e+16</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 22:02:20,028\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/tiennv/ray_results/train_model_2024-09-22_22-01-57' in 0.0442s.\n",
      "2024-09-22 22:02:20,057\tINFO tune.py:1041 -- Total run time: 23.07 seconds (22.90 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'stock_data_file': '/home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/Datasets/technology_ver_1.csv', 'batch_size': 128, 'split_ratio': 0.8, 'calculate_technical_indicators': True, 'rolling_window': 30, 'lr': 0.007198013043215177, 'optimizer': 'Adam', 'momentum': 0.8776486243327521, 'weight_decay': 4.942669666368748e-05, 'scheduler': 'StepLR', 'step_size': 20, 'gamma': 0.45763252076024297, 'ts_size': 60, 'mask_size': 1, 'num_masks': 2, 'hidden_dim': 24, 'embed_dim': 6, 'num_layer': 4, 'z_dim': 20, 'num_embed': 64, 'num_samples': 20, 'epochs': 10, 'max_num_epochs': 100, 'gpus_per_trial': 0, 'grace_period': 1, 'reduction_factor': 2, 'device': 'cpu', 'stock_features': ['Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume', 'stoch', 'adx', 'bollinger_hband', 'mfi', 'rsi', 'ma', 'std', 'adl', 'williams', 'macd', 'obv', 'sar', 'ichimoku_a', 'ichimoku_b'], 'min_val': array([ 4.59453315e-01,  4.78500009e-01,  4.87500012e-01,  4.73500013e-01,\n",
      "        4.81249988e-01,  0.00000000e+00,  0.00000000e+00,  3.21805341e+00,\n",
      "        7.38272562e+01,  1.73447777e+00,  4.23946742e+01,  2.48179424e+01,\n",
      "        2.15548392e+01, -2.17302467e+09, -1.00000000e+02, -1.33643311e+01,\n",
      "       -1.23974206e+11,  4.64983580e+01,  3.42043750e+01,  4.47023738e+01]), 'max_val': array([ 1.85039658e+02,  1.94830002e+02,  1.95929993e+02,  1.93380005e+02,\n",
      "        1.95000000e+02,  1.40524800e+09,  1.00000000e+02,  9.20426719e+00,\n",
      "        1.82642077e+02,  9.92617096e+01,  6.50187234e+01,  1.00782710e+02,\n",
      "        5.47552574e+01,  7.10742327e+09, -0.00000000e+00,  2.47550200e+01,\n",
      "       -6.81279730e+07,  1.95929993e+02,  1.13479998e+02,  1.01789998e+02])}\n",
      "Best trial final validation loss: 1000000000.0\n"
     ]
    }
   ],
   "source": [
    "import ray.train\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "\n",
    "\n",
    "# Bước 2: Hàm training với Ray Tune và validation\n",
    "def train_model(config, checkpoint_dir=None):\n",
    "    # ---------------- Get Model ------------\n",
    "    model = StockEmbedder(config={k: config[k] for k in ['ts_size', 'mask_size', 'num_masks', 'hidden_dim', 'embed_dim', 'num_layer', 'z_dim', 'num_embed', 'min_val', 'max_val', 'stock_features']})\n",
    "    \n",
    "    train_batches, val_batches = create_batches(config=config)\n",
    "    # ---------------- END OF: Get Model -------------\n",
    "    \n",
    "    criterion = torch.nn.MSELoss(reduction='mean')\n",
    "    optimizer = getattr(optim, config[\"optimizer\"])(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    # Chỉ dùng momentum nếu optimizer là SGD\n",
    "    if config[\"optimizer\"] == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    # Load checkpoint nếu có\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = torch.load(checkpoint_dir)\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "    \n",
    "    \n",
    "    pseudo_masks = generate_pseudo_masks(ts_size=model.config['ts_size'], num_samples=config['batch_size'])\n",
    "    \n",
    "    # ------------------- TRAIN AE ----------------------------\n",
    "    # for t in tqdm(range(config['epochs'])):\n",
    "    #     # ------------ Train model: -----------------\n",
    "    #     # Đặt mô hình về chế độ train để huấn luyện\n",
    "    #     model.train()\n",
    "        \n",
    "    #     x_ori = get_mini_batch(batch_size=config['batch_size'], data=train_batches)  # (bs, ts_size, z_dim)\n",
    "        \n",
    "    #     x_ori = torch.tensor(x_ori, dtype=torch.float32).to(config['device'])\n",
    "    #     x_enc, x_dec = model(x_ori, pseudo_masks, 'ae')\n",
    "    #     loss = criterion(x_dec, x_ori)\n",
    "        \n",
    "    #     optimizer.zero_grad()\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()\n",
    "        \n",
    "    #     # -------------- END OF: Train model -----------------\n",
    "    #     # ------------- Calculate loss on validation set: -----------------------\n",
    "    #     model.eval()\n",
    "        \n",
    "    #     val_loss = 0\n",
    "        \n",
    "    #     num_batches = len(val_batches) // config['batch_size']\n",
    "        \n",
    "    #     for i in range(num_batches):\n",
    "    #         # Lấy batch dữ liệu\n",
    "    #         val_batch = val_batches[i * config['batch_size'] : (i + 1) * config['batch_size']]  # (bs, ts_size, z_dim)\n",
    "            \n",
    "    #         x_ori = torch.tensor(val_batch, dtype=torch.float32).to(config['device'])\n",
    "    #         x_enc, x_dec = model(x_ori, pseudo_masks, 'ae')\n",
    "    #         loss = criterion(x_dec, x_ori)\n",
    "            \n",
    "    #         # Cộng dồn loss cho mỗi batch\n",
    "    #         val_loss += loss.item()\n",
    "        \n",
    "    #     # Tính trung bình của val_loss\n",
    "    #     if num_batches > 0:\n",
    "    #         val_loss /= num_batches\n",
    "    #     else:\n",
    "    #         val_loss = 1e9\n",
    "        \n",
    "    #     # ------------- END OF: Calculate loss on validation set: -----------------------\n",
    "        \n",
    "        \n",
    "    #     # Báo cáo loss trên tập validation cho Ray Tune\n",
    "    #     ray.train.report({'loss': val_loss})\n",
    "    \n",
    "    # ------------------- END OF: TRAIN AE ----------------------------\n",
    "    \n",
    "    \n",
    "    # ------------------- TRAIN EMBED ----------------------------\n",
    "    # for t in tqdm(range(config['epochs'])):\n",
    "    #     # ------------ Train model: -----------------\n",
    "    #     x_ori = get_mini_batch(batch_size=config['batch_size'], data=train_batches)  # (bs, ts_size, z_dim)\n",
    "        \n",
    "    #     x_ori = torch.tensor(x_ori, dtype=torch.float32).to(config['device'])\n",
    "    #     random_masks = generate_random_masks(num_samples=config['batch_size'], ts_size=model.config['ts_size'], mask_size=model.config['mask_size'], num_masks=model.config['num_masks'])\n",
    "\n",
    "    #     # Get the target x_ori_enc by Autoencoder\n",
    "    #     model.eval()\n",
    "    #     masks = pseudo_masks\n",
    "    #     x_ori_enc, _ = model(x_ori, pseudo_masks, 'ae')\n",
    "    #     x_ori_enc = x_ori_enc.clone().detach()  # (bs, ts_size, hidden_dim)\n",
    "    #     b, l, f = x_ori_enc.size()\n",
    "\n",
    "    #     model.train()\n",
    "    #     masks = random_masks\n",
    "    #     x_enc, x_inter, x_dec = model(x_ori, random_masks, 'mae')\n",
    "\n",
    "    #     # Only calculate loss for those being masked\n",
    "    #     x_enc_masked = x_enc[masks, :].reshape(b, -1, f)\n",
    "    #     x_ori_enc_masked = x_ori_enc[masks, :].reshape(b, -1, f)\n",
    "    #     loss = criterion(x_enc_masked, x_ori_enc_masked)\n",
    "    #     # By annotate lines above, we take loss on all patches\n",
    "    #     # loss = self.criterion(x_enc, x_ori_enc)  # embed_loss\n",
    "        \n",
    "    #     optimizer.zero_grad()\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()\n",
    "        \n",
    "    #     # -------------- END OF: Train model -----------------\n",
    "    #     # ------------- Calculate loss on validation set: -----------------------\n",
    "    #     model.eval()\n",
    "        \n",
    "    #     val_loss = 0\n",
    "        \n",
    "    #     num_batches = len(val_batches) // config['batch_size']\n",
    "        \n",
    "    #     for i in range(num_batches):\n",
    "    #         # Lấy batch dữ liệu\n",
    "    #         val_batch = val_batches[i * config['batch_size'] : (i + 1) * config['batch_size']]  # (bs, ts_size, z_dim)\n",
    "            \n",
    "    #         x_ori = torch.tensor(val_batch, dtype=torch.float32).to(config['device'])\n",
    "    #         random_masks = generate_random_masks(num_samples=config['batch_size'], ts_size=model.config['ts_size'], mask_size=model.config['mask_size'], num_masks=model.config['num_masks'])  # (bs, ts_size)\n",
    "            \n",
    "    #         # Get the target x_ori_enc by Autoencoder\n",
    "    #         masks = pseudo_masks\n",
    "    #         x_ori_enc, _ = model(x_ori, pseudo_masks, 'ae')\n",
    "    #         x_ori_enc = x_ori_enc.clone().detach()  # (bs, ts_size, hidden_dim)\n",
    "    #         b, l, f = x_ori_enc.size()\n",
    "            \n",
    "    #         masks = random_masks\n",
    "    #         x_enc, x_inter, x_dec = model(x_ori, random_masks, 'mae')\n",
    "\n",
    "    #         # Only calculate loss for those being masked\n",
    "    #         x_enc_masked = x_enc[masks, :].reshape(b, -1, f)\n",
    "    #         x_ori_enc_masked = x_ori_enc[masks, :].reshape(b, -1, f)\n",
    "    #         loss = criterion(x_enc_masked, x_ori_enc_masked)\n",
    "    #         # By annotate lines above, we take loss on all patches\n",
    "    #         # loss = self.criterion(x_enc, x_ori_enc)  # embed_loss\n",
    "            \n",
    "    #         # Cộng dồn loss cho mỗi batch\n",
    "    #         val_loss += loss.item()\n",
    "        \n",
    "    #     # Tính trung bình của val_loss\n",
    "    #     if num_batches > 0:\n",
    "    #         val_loss /= num_batches\n",
    "    #     else:\n",
    "    #         val_loss = 1e9\n",
    "        \n",
    "    #     # ------------- END OF: Calculate loss on validation set: -----------------------\n",
    "        \n",
    "    #     # Báo cáo loss trên tập validation cho Ray Tune\n",
    "    #     ray.train.report({'loss': val_loss})\n",
    "        \n",
    "    # ------------------- END OF: TRAIN EMBED ----------------------------\n",
    "    \n",
    "    \n",
    "    # ------------------- TRAIN RECON ----------------------------\n",
    "    for t in tqdm(range(config['epochs'])):\n",
    "        # ------------ Train model: -----------------\n",
    "        x_ori = get_mini_batch(batch_size=config['batch_size'], data=train_batches)  # (bs, ts_size, z_dim)\n",
    "        \n",
    "        x_ori = torch.tensor(x_ori, dtype=torch.float32).to(config['device'])\n",
    "        random_masks = generate_random_masks(num_samples=config['batch_size'], ts_size=model.config['ts_size'], mask_size=model.config['mask_size'], num_masks=model.config['num_masks'])  # (bs, ts_size)\n",
    "\n",
    "        model.train()\n",
    "        masks = random_masks\n",
    "        _, x_inter, x_dec = model(x_ori, random_masks, 'mae')\n",
    "        loss = criterion(x_dec, x_ori)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # -------------- END OF: Train model -----------------\n",
    "        # ------------- Calculate loss on validation set: -----------------------\n",
    "        model.eval()\n",
    "        \n",
    "        val_loss = 0\n",
    "        \n",
    "        num_batches = len(val_batches) // config['batch_size']\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            # Lấy batch dữ liệu\n",
    "            val_batch = val_batches[i * config['batch_size'] : (i + 1) * config['batch_size']]  # (bs, ts_size, z_dim)\n",
    "            \n",
    "            x_ori = torch.tensor(val_batch, dtype=torch.float32).to(config['device'])\n",
    "            random_masks = generate_random_masks(num_samples=config['batch_size'], ts_size=model.config['ts_size'], mask_size=model.config['mask_size'], num_masks=model.config['num_masks'])  # (bs, ts_size)\n",
    "            \n",
    "            masks = random_masks\n",
    "            _, x_inter, x_dec = model(x_ori, random_masks, 'mae')\n",
    "            loss = criterion(x_dec, x_ori)\n",
    "            \n",
    "            # Cộng dồn loss cho mỗi batch\n",
    "            val_loss += loss.item()\n",
    "        \n",
    "        # Tính trung bình của val_loss\n",
    "        if num_batches > 0:\n",
    "            val_loss /= num_batches\n",
    "        else:\n",
    "            val_loss = 1e9\n",
    "        \n",
    "        # ------------- END OF: Calculate loss on validation set: -----------------------\n",
    "        \n",
    "        #  Báo cáo loss trên tập validation cho Ray Tune\n",
    "        ray.train.report({'loss': val_loss})\n",
    "        \n",
    "    # ------------------- END OF: TRAIN RECON ----------------------------\n",
    "        \n",
    "        \n",
    "\n",
    "# Bước 3: Cấu hình hyperparameter tuning\n",
    "def main():\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",  # Sử dụng loss trên tập validation để đánh giá\n",
    "        mode=\"min\",\n",
    "        max_t=config['max_num_epochs'],\n",
    "        grace_period=config['grace_period'],\n",
    "        reduction_factor=config['reduction_factor']\n",
    "    )\n",
    "    \n",
    "    result = tune.run(\n",
    "        # train_model,\n",
    "        tune.with_parameters(trainable=train_model),\n",
    "        resources_per_trial={\"cpu\": 1, \"gpu\": config['gpus_per_trial']},\n",
    "        config=config,\n",
    "        num_samples=config['num_samples'],\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
    "    \n",
    "    return best_trial\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_trial = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stock_data_file': '/home/tiennv/FPT/FinanceTransformers/Models_Development/Stock_Embedder/Datasets/technology_ver_1.csv',\n",
       " 'batch_size': 128,\n",
       " 'split_ratio': 0.8,\n",
       " 'calculate_technical_indicators': True,\n",
       " 'rolling_window': 30,\n",
       " 'lr': 0.007198013043215177,\n",
       " 'optimizer': 'Adam',\n",
       " 'momentum': 0.8776486243327521,\n",
       " 'weight_decay': 4.942669666368748e-05,\n",
       " 'scheduler': 'StepLR',\n",
       " 'step_size': 20,\n",
       " 'gamma': 0.45763252076024297,\n",
       " 'ts_size': 60,\n",
       " 'mask_size': 1,\n",
       " 'num_masks': 2,\n",
       " 'hidden_dim': 24,\n",
       " 'embed_dim': 6,\n",
       " 'num_layer': 4,\n",
       " 'z_dim': 20,\n",
       " 'num_embed': 64,\n",
       " 'num_samples': 20,\n",
       " 'epochs': 10,\n",
       " 'max_num_epochs': 100,\n",
       " 'gpus_per_trial': 0,\n",
       " 'grace_period': 1,\n",
       " 'reduction_factor': 2,\n",
       " 'device': 'cpu',\n",
       " 'stock_features': ['Adj Close',\n",
       "  'Close',\n",
       "  'High',\n",
       "  'Low',\n",
       "  'Open',\n",
       "  'Volume',\n",
       "  'stoch',\n",
       "  'adx',\n",
       "  'bollinger_hband',\n",
       "  'mfi',\n",
       "  'rsi',\n",
       "  'ma',\n",
       "  'std',\n",
       "  'adl',\n",
       "  'williams',\n",
       "  'macd',\n",
       "  'obv',\n",
       "  'sar',\n",
       "  'ichimoku_a',\n",
       "  'ichimoku_b'],\n",
       " 'min_val': array([ 4.59453315e-01,  4.78500009e-01,  4.87500012e-01,  4.73500013e-01,\n",
       "         4.81249988e-01,  0.00000000e+00,  0.00000000e+00,  3.21805341e+00,\n",
       "         7.38272562e+01,  1.73447777e+00,  4.23946742e+01,  2.48179424e+01,\n",
       "         2.15548392e+01, -2.17302467e+09, -1.00000000e+02, -1.33643311e+01,\n",
       "        -1.23974206e+11,  4.64983580e+01,  3.42043750e+01,  4.47023738e+01]),\n",
       " 'max_val': array([ 1.85039658e+02,  1.94830002e+02,  1.95929993e+02,  1.93380005e+02,\n",
       "         1.95000000e+02,  1.40524800e+09,  1.00000000e+02,  9.20426719e+00,\n",
       "         1.82642077e+02,  9.92617096e+01,  6.50187234e+01,  1.00782710e+02,\n",
       "         5.47552574e+01,  7.10742327e+09, -0.00000000e+00,  2.47550200e+01,\n",
       "        -6.81279730e+07,  1.95929993e+02,  1.13479998e+02,  1.01789998e+02])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinTrans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
